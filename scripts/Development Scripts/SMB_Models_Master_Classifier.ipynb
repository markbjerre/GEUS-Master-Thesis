{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Mass Balance: XGB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTbsuMgO3ery"
   },
   "source": [
    "Import relevant Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyarrow) (1.22.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (5.13.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from plotly) (8.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: feature_engine in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from feature_engine) (1.22.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from feature_engine) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from feature_engine) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from feature_engine) (1.5.4)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from feature_engine) (0.13.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2020.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (2.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (23.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ERROR: unknown command \"update\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow\n",
    "%pip install plotly\n",
    "%pip install feature_engine\n",
    "%pip update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yJLqdDNx3j-Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Nils\\\\Master_Thesis\\\\scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math as math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Set WD\n",
    "import os\n",
    "from pyrsistent import v\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load KAN_L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r'..\\data\\promice\\preprocessed\\daily\\KAN_L.csv', index_col=0)\n",
    "df = pd.read_csv(r'../data/promice/preprocessed/daily/SCO_L.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load SCO_L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r'..\\data\\promice\\preprocessed\\daily\\KAN_L.csv', index_col=0)\n",
    "df_1 = pd.read_csv(r'../data/promice/preprocessed/daily/KAN_L.csv', index_col=0)\n",
    "\n",
    "df = df.append(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing (0.1: Change months to cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to change the datetime variables into a form that a ML models can understand\n",
    "  # https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/\n",
    "  # https://feature-engine.trainindata.com/en/1.3.x/user_guide/creation/CyclicalFeatures.html\n",
    "    \n",
    "    \n",
    "# This bit to split Datetime column into year, month, day, hour columns\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df['Datetime'] = df['Datetime'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "#Create new columns\n",
    "#df['year'] = df['Datetime'].dt.year \n",
    "df['month'] = df['Datetime'].dt.month\n",
    "#df['day'] = df['Datetime'].dt.day\n",
    "#df['hour'] = df['Datetime'].dt.hour\n",
    "\n",
    "#Drop the datetime column\n",
    "df.drop(columns=['Datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to change the datetime variables into a form that a ML models can understand (continued)\n",
    "  # https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/\n",
    "  # https://feature-engine.trainindata.com/en/1.3.x/user_guide/creation/CyclicalFeatures.html \n",
    "\n",
    "# Use CyclicalFeatures Package to convert year, month, day & hour\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "\n",
    "cyclical = CyclicalFeatures(variables=None, drop_original=True)\n",
    "\n",
    "# with year\n",
    "#cyclical = cyclical.fit_transform(df[['month', 'year', 'Wind from direction (upper boom)']]) \n",
    "\n",
    "# Remove only values from Wind direction because CyclicalFeatures does not work with NAN\n",
    "df = df[df['Wind from direction (upper boom)'].notna()] \n",
    "\n",
    "# without year\n",
    "#cyclical = cyclical.fit_transform(df[['month', 'Wind from direction (upper boom)']]) \n",
    "cyclical = cyclical.fit_transform(df[['Wind from direction (upper boom)']]) \n",
    "df = pd.merge(df, cyclical, left_index=True, right_index=True)\n",
    "\n",
    "df.drop(columns=['month', 'Wind from direction (upper boom)'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing (1.0: Filter relevant periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in Melting season as blank\n",
    "df['Melting Season'] = df['Melting Season'].fillna('no_ablation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only Ablation Period Or Melting Season\n",
    "df = df[df['Ablation'] == True]\n",
    "#df =  df[df['Melting Season'].isin(['pre', 'beginning', 'middle', 'end'])]\n",
    "\n",
    "#Remove all NA values if training should be done only on ablation\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit retrieve the indexes for all melting season categories and remove column from df\n",
    "for category in ['no_ablation', 'pre', 'beginning', 'middle', 'end']:\n",
    "    exec(f\"indices_{category} = df[df['Melting Season'] == '{category}'].index\")\n",
    "\n",
    "# This bit retrieve the indexes for Ablation periods\n",
    "for category in [True]:\n",
    "    exec(f\"indices_ablation = df[df['Ablation'] == {category}].index\")\n",
    "\n",
    "indices_all = df[df['Ablation'].isin([True, False])].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing (2.0: Formatting and transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "df['Melting Season'] = le.fit_transform(df['Melting Season'])\n",
    "label_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "class_order = ['no_ablation', 'pre', 'beginning', 'middle', 'end']\n",
    "\n",
    "# Sort the label_dict based on the desired order of class names\n",
    "label_dict_sorted = {class_name: label_dict[class_name] for class_name in class_order if class_name in label_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to include only relevant features\n",
    "exclude_list = [                                                    'index', # excluded because of unimportant information\n",
    "                                                                     'stid', # excluded because of unimportant information\n",
    "                                                               'Unnamed: 0', # Old Index\n",
    "                                                                 'Ablation',\n",
    "                                                          # 'Melting Season', # We drop melting season later \n",
    "                                              'year', 'month','day', 'hour', # Drop because of sin & cos values\n",
    "                                                                 'subgroup',\n",
    "                'Surface height from combined measurements',\n",
    "                'Surface height from combined measurements DELTA'\n",
    "               ]\n",
    "\n",
    "df = df[[column for column in df.columns if column not in exclude_list]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to convert all numerical values into the same scale \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "\n",
    "# with year\n",
    "#num_cols = df.select_dtypes(include=['int64','float64']).drop(['Surface height from combined measurements', 'Surface height from combined measurements DELTA','month_sin','month_cos','year_sin','year_cos','Wind from direction (upper boom)_sin', 'Wind from direction (upper boom)_cos', 'Melting Season'], axis=1).columns #select numerical columns except y and cyclical feature\n",
    "\n",
    "# without year\n",
    "#num_cols = df.select_dtypes(include=['int64','float64']).drop(['month_sin','month_cos','Wind from direction (upper boom)_sin', 'Wind from direction (upper boom)_cos', 'Melting Season'], axis=1).columns #select numerical columns except y and cyclical feature\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).drop(['Wind from direction (upper boom)_sin', 'Wind from direction (upper boom)_cos'], axis=1).columns #select numerical columns except y and cyclical feature\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#fit and transform numerical columns\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to split into Train & Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split the data into training and testing sets while maintaining the subgroup distribution\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(df, df['Melting Season']):\n",
    "    train = df.loc[train_index]\n",
    "    test = df.loc[test_index]\n",
    "\n",
    "# separate the features and target variables for the train and test sets\n",
    "X_train = train.drop(['Melting Season'], axis=1)\n",
    "y_train = train['Melting Season']\n",
    "X_test = test.drop(['Melting Season'], axis=1)\n",
    "y_test = test['Melting Season']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Multinomial Regression\n",
      "Accuracy score on test set: 0.8361650485436893\n",
      "F1 score on test set: 0.8205935579509974\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         52    0      77\n",
      "end                0   82      37\n",
      "middle            14    7     555\n",
      "Accuracy per class:\n",
      "Class 0: 0.40310077519379844\n",
      "Class 1: 0.6890756302521008\n",
      "Class 2: 0.9635416666666666\n",
      "--------------------\n",
      "Evaluating K-Nearest Neighbors\n",
      "Accuracy score on test set: 0.8118932038834952\n",
      "F1 score on test set: 0.8029524291558784\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         63    0      66\n",
      "end                0   75      44\n",
      "middle            34   11     531\n",
      "Accuracy per class:\n",
      "Class 0: 0.4883720930232558\n",
      "Class 1: 0.6302521008403361\n",
      "Class 2: 0.921875\n",
      "--------------------\n",
      "Evaluating SVM\n",
      "Accuracy score on test set: 0.8361650485436893\n",
      "F1 score on test set: 0.8172117501271972\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         47    0      82\n",
      "end                0   83      36\n",
      "middle             7   10     559\n",
      "Accuracy per class:\n",
      "Class 0: 0.3643410852713178\n",
      "Class 1: 0.6974789915966386\n",
      "Class 2: 0.9704861111111112\n",
      "--------------------\n",
      "Evaluating RBF SVM\n",
      "Accuracy score on test set: 0.787621359223301\n",
      "F1 score on test set: 0.7286461124624253\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning          8    0     121\n",
      "end                0   70      49\n",
      "middle             0    5     571\n",
      "Accuracy per class:\n",
      "Class 0: 0.06201550387596899\n",
      "Class 1: 0.5882352941176471\n",
      "Class 2: 0.9913194444444444\n",
      "--------------------\n",
      "Evaluating Gaussian Process\n",
      "Accuracy score on test set: 0.8216019417475728\n",
      "F1 score on test set: 0.7993082287188269\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         43    0      86\n",
      "end                0   75      44\n",
      "middle             8    9     559\n",
      "Accuracy per class:\n",
      "Class 0: 0.3333333333333333\n",
      "Class 1: 0.6302521008403361\n",
      "Class 2: 0.9704861111111112\n",
      "--------------------\n",
      "Evaluating Decision Tree\n",
      "Accuracy score on test set: 0.7839805825242718\n",
      "F1 score on test set: 0.7826268742333417\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         69    2      58\n",
      "end                2   81      36\n",
      "middle            56   24     496\n",
      "Accuracy per class:\n",
      "Class 0: 0.5348837209302325\n",
      "Class 1: 0.680672268907563\n",
      "Class 2: 0.8611111111111112\n",
      "--------------------\n",
      "Evaluating Random Forest\n",
      "Accuracy score on test set: 0.8410194174757282\n",
      "F1 score on test set: 0.8344569532950395\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         71    1      57\n",
      "end                0   84      35\n",
      "middle            27   11     538\n",
      "Accuracy per class:\n",
      "Class 0: 0.5503875968992248\n",
      "Class 1: 0.7058823529411765\n",
      "Class 2: 0.9340277777777778\n",
      "--------------------\n",
      "Evaluating Neural Net\n",
      "Accuracy score on test set: 0.8555825242718447\n",
      "F1 score on test set: 0.8532036915270608\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         85    0      44\n",
      "end                0   92      27\n",
      "middle            27   21     528\n",
      "Accuracy per class:\n",
      "Class 0: 0.6589147286821705\n",
      "Class 1: 0.773109243697479\n",
      "Class 2: 0.9166666666666666\n",
      "--------------------\n",
      "Evaluating AdaBoost\n",
      "Accuracy score on test set: 0.7439320388349514\n",
      "F1 score on test set: 0.725953501388006\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         27    0     102\n",
      "end                0   85      34\n",
      "middle            51   24     501\n",
      "Accuracy per class:\n",
      "Class 0: 0.20930232558139536\n",
      "Class 1: 0.7142857142857143\n",
      "Class 2: 0.8697916666666666\n",
      "--------------------\n",
      "Evaluating Naive Bayes\n",
      "Accuracy score on test set: 0.7694174757281553\n",
      "F1 score on test set: 0.7689345489207629\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         66    1      62\n",
      "end                3   75      41\n",
      "middle            68   15     493\n",
      "Accuracy per class:\n",
      "Class 0: 0.5116279069767442\n",
      "Class 1: 0.6302521008403361\n",
      "Class 2: 0.8559027777777778\n",
      "--------------------\n",
      "Evaluating QDA\n",
      "Accuracy score on test set: 0.8252427184466019\n",
      "F1 score on test set: 0.8262768983789823\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         92    1      36\n",
      "end                0   85      34\n",
      "middle            53   20     503\n",
      "Accuracy per class:\n",
      "Class 0: 0.7131782945736435\n",
      "Class 1: 0.7142857142857143\n",
      "Class 2: 0.8732638888888888\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "labels = [k for k, v in sorted(label_dict.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Define a dictionary of models and their hyperparameters\n",
    "models = {\n",
    "    'Multinomial Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000),\n",
    "    'K-Nearest Neighbors':  KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='linear', C=1.0),\n",
    "    'RBF SVM':  SVC(kernel='rbf', C=1.0, gamma='auto'),\n",
    "    'Gaussian Process': GaussianProcessClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Neural Net': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}\")\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model's performance on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy score on test set: {accuracy}\")\n",
    "    print(f\"F1 score on test set: {f1}\")\n",
    "    print(\"Confusion matrix on test set: \")\n",
    "    print(pd.DataFrame(cm, index=labels, columns=labels))\n",
    "    print(\"Accuracy per class:\")\n",
    "    for i in range(len(labels)):\n",
    "        acc = accuracy_score(y_test[y_test == i], y_pred[y_test == i])\n",
    "        print(f\"Class {i}: {acc}\")\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best hyperparameters:  {'activation': 'relu', 'alpha': 0.001, 'early_stopping': False, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
      "Accuracy score on test set:  0.8580097087378641\n",
      "F1 score on test set:  0.8557268635729134\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         86    0      43\n",
      "end                0   92      27\n",
      "middle            27   20     529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 50), (200, 100, 50)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'early_stopping': [True, False],\n",
    "   # 'dropout': [0.0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Define the neural network model\n",
    "model = MLPClassifier(max_iter=1000)\n",
    "\n",
    "# Define the grid search object\n",
    "grid_search = GridSearchCV(model, param_grid = param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score on the test set\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Accuracy score on test set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score on test set: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "labels = [k for k, v in sorted(label_dict.items(), key=lambda item: item[1])]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(cm_df)\n",
    "print(\"Accuracy per class:\")\n",
    "for i in range(len(labels)):\n",
    "    acc = accuracy_score(y_test[y_test == i], y_pred[y_test == i])\n",
    "    print(f\"Class {i}: {acc}\")\n",
    "print(\"--------------------\")\n",
    "\n",
    "# Save the best model parameters as 'model' variable\n",
    "model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best hyperparameters:  {'priors': None, 'reg_param': 0.0, 'store_covariance': True, 'tol': 0.0001}\n",
      "Accuracy score on test set:  0.8250974025974026\n",
      "F1 score on test set:  0.8254205938453965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   beginning       0.63      0.71      0.67       129\n",
      "         end       0.80      0.71      0.76       119\n",
      "      middle       0.88      0.87      0.88       576\n",
      "\n",
      "    accuracy                           0.83       824\n",
      "   macro avg       0.77      0.77      0.77       824\n",
      "weighted avg       0.83      0.83      0.83       824\n",
      "\n",
      "Accuracy per class:\n",
      "Class 0: 0.7131782945736435\n",
      "Class 1: 0.7142857142857143\n",
      "Class 2: 0.8732638888888888\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'reg_param': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'store_covariance': [True, False],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'priors': [None, [0.3, 0.3, 0.4], [0.2, 0.2, 0.6]]\n",
    "}\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Define the QDA classifier\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Define the grid search object\n",
    "grid_search = GridSearchCV(qda, param_grid=param_grid, cv=cv, scoring=scoring, refit='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding scores on the test set\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy score on test set: \", grid_search.best_score_)\n",
    "print(\"F1 score on test set: \", grid_search.cv_results_['mean_test_f1_score'][grid_search.best_index_])\n",
    "\n",
    "# Evaluate the performance on the test set using the best estimator\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "\n",
    "print(\"Accuracy per class:\")\n",
    "for i in range(len(labels)):\n",
    "    acc = accuracy_score(y_test[y_test == i], y_pred[y_test == i])\n",
    "    print(f\"Class {i}: {acc}\")\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nifu18ab\\AppData\\Local\\Temp\\2/ipykernel_8956/3815655594.py:39: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 100, 'learning_rate': 0.001}\n",
      "Accuracy score on test set: 0.8434466019417476\n",
      "F1 score on test set: 0.8388609101209606\n",
      "Confusion matrix on test set: \n",
      "           beginning  end  middle\n",
      "beginning         80    0      49\n",
      "end                1   81      37\n",
      "middle            29   13     534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a function that returns a compiled neural network model\n",
    "def create_model(learning_rate=0.01, dropout_rate=0.0):\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add a fully connected layer with 100 neurons and input shape of the number of features\n",
    "    model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "    \n",
    "    # Add dropout layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Add another fully connected layer with 50 neurons\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    \n",
    "    # Add a final fully connected layer with number of neurons equal to the number of classes and softmax activation\n",
    "    model.add(Dense(len(label_dict), activation='softmax'))\n",
    "    \n",
    "    # Compile the model with categorical cross-entropy loss, Adam optimizer, and accuracy metric\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.0, 0.1, 0.2],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [50, 100]\n",
    "}\n",
    "\n",
    "# Create a grid search object with the model and hyperparameters\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_result = grid_search.fit(X_train, tf.keras.utils.to_categorical(y_train))\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score on the test set\n",
    "print(f\"Best hyperparameters: {grid_result.best_params_}\")\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy score on test set: {accuracy}\")\n",
    "print(f\"F1 score on test set: {f1}\")\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(pd.DataFrame(cm, index=labels, columns=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per class:\n",
      "Class 0: 0.6201550387596899\n",
      "Class 1: 0.680672268907563\n",
      "Class 2: 0.9270833333333334\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy per class:\")\n",
    "for i in range(len(labels)):\n",
    "    acc = accuracy_score(y_test[y_test == i], y_pred[y_test == i])\n",
    "    print(f\"Class {i}: {acc}\")\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
