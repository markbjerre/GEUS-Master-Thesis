{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTbsuMgO3ery"
   },
   "source": [
    "Import relevant Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yJLqdDNx3j-Y"
   },
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math as math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "# Visualizations\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ODOhsaMP7u_"
   },
   "source": [
    "Set WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\nifu18ab\\\\Desktop\\\\GEUS-Master-Thesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data):\n",
    "    # Ignore Warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Load data\n",
    "    if data == \"GC Net\":\n",
    "        df = pd.read_parquet('data\\df_daily.gzip', engine='pyarrow')\n",
    "    elif data == \"Promice\":\n",
    "        df = pd.read_parquet('data\\promice_daily.gzip', engine='pyarrow')\n",
    "    else: \n",
    "        raise ValueError(\"Only 'GC Net' & 'Promice' are accepted input values\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _align_GC_PR():\n",
    "    station = \"file\"\n",
    "    datetime = \"Datetime\"\n",
    "    dayofcentury = \"DayOfCentury\"\n",
    "    dayofyear = 'DayOfYear'\n",
    "    return station,datetime,dayofcentury,dayofyear\n",
    "\n",
    "def _exclude():\n",
    "    # List of columns to exclude from percentile calculation\n",
    "    exclude = ['Year', 'MonthOfYear', 'DayOfMonth', 'HourOfDay(UTC)', \n",
    "               'DayOfYear', 'LongitudeGPS(degW)','HeightStakes(m)',\n",
    "               'DayOfCentury', 'WindDirection(d)', 'TiltToEast(d)', \n",
    "               'TiltToNorth(d)', 'TimeGPS(hhmmssUTC)', 'LatitudeGPS(degN)', \n",
    "               'ElevationGPS(m)', 'HorDilOfPrecGPS', 'LoggerTemperature(C)',\n",
    "               'FanCurrent(mA)', 'BatteryVoltage(V)', 'Month', 'Day', 'Hour',\n",
    "\n",
    "              'air_temperature_1_max', 'air_temperature_1_min',\n",
    "              'wind_speed_u1_max','wind_speed_u2_max',\n",
    "              'wind_from_direction_1', 'wind_from_direction_2', \n",
    "              'height_wind_sensor_1', 'height_wind_sensor_2', 'battery_voltage',\n",
    "              'shortwave_incoming_radiation_max',\n",
    "              'shortwave_incoming_radiation_stdev', 'net_radiation_stdev',\n",
    "              'air_temperature_2_max', 'air_temperature_2_min', \n",
    "              'wind_speed_u2_stdev', 'ref_temperature',   'wind_speed_u1_stdev',\n",
    "              'net_radiation_maximum', 'season', 'year', 'month', 'DayOfYear',\n",
    "              'DayOfCentury']\n",
    "    return exclude\n",
    "\n",
    "def _subset_df(date, df, station, datetime, measurement, dayofcentury, dayofyear, aws):\n",
    "    exclude = _exclude()\n",
    "    \n",
    "    # Split date input into year, month, day\n",
    "    year = int(date[0:4])\n",
    "    month = int(date[5:7])\n",
    "    day = int(date[8:10])\n",
    "\n",
    "    # Subset df with date\n",
    "    date_df = df.loc[(df['Datetime'].dt.year == year) & (df['Datetime'].dt.month == month) & (df['Datetime'].dt.day == day)]\n",
    "    \n",
    "    # Find the day of year\n",
    "    day =  date_df[\"DayOfYear\"].mean()\n",
    "    \n",
    "    # find day of century\n",
    "    day_century = date_df[dayofcentury].mean() \n",
    "    \n",
    "    #Create a list of relevant columns\n",
    "    columns = df.select_dtypes(include=[np.number]).columns.difference(exclude)\n",
    "\n",
    "    ## Subset by measurement\n",
    "        #df = df[[station,datetime, measurement, dayofcentury,dayofyear]]\n",
    "    if measurement == \"All\":\n",
    "        df = df\n",
    "    elif measurement in columns:\n",
    "        # subset by measurement\n",
    "        df = df[[station,datetime, measurement, dayofcentury, dayofyear]]\n",
    "        #Update list of relevant column\n",
    "        columns = df.select_dtypes(include=[np.number]).columns.difference(exclude)\n",
    "    else: \n",
    "        raise ValueError(f\"The input for the variable 'measurement' was not recognizable. Please use one of the following options: {columns}\")\n",
    "    \n",
    "    ## Subset by station\n",
    "        #df = df.loc[df[station] == aws]\n",
    "    #Create a list of unique files (stations) from the dataset \n",
    "    unique_files = list(df[station].unique())\n",
    "    if aws == \"All\":\n",
    "        df = df\n",
    "    elif aws in unique_files:\n",
    "        # filter by aws\n",
    "        df = df.loc[df[station] == aws]\n",
    "        #Update list of unique files (stations) from the dataset \n",
    "        unique_files = list(df[station].unique())\n",
    "    else: \n",
    "        raise ValueError(f\"The input for the variable 'aws' was not recognizable. Please use one of the following options: {unique_files}\")\n",
    "    \n",
    "    return day, df,columns, day_century, unique_files\n",
    "\n",
    "def _subset_scope(scope, df,day, dayofyear):\n",
    "    if scope == \"Relative\":\n",
    "        # filter by calender day\n",
    "        df = df.loc[df[dayofyear] == day]\n",
    "    elif scope == \"Absolute\":\n",
    "        df = df\n",
    "    else: \n",
    "        raise ValueError(\"The input for the variable 'scope' was not recognizable. Please use one of the following options: 'Relative' , 'Absolute'\")\n",
    "    return df\n",
    "\n",
    "def _percentiles(df, unique_files, station, columns,dayofcentury,day_century):\n",
    "        #Create an empty list to hold the percentile values\n",
    "    percentiles = []\n",
    "\n",
    "    print(\"Calculating Percentiles .... \")\n",
    "    #Loop through each file in the unique_files list\n",
    "    for i, file in enumerate(unique_files):\n",
    "        \n",
    "        #Calculate the percentile of each numerical column for the specified datetime\n",
    "        df_file = df[df[station] == file]\n",
    "\n",
    "        #Create an empty dictionary\n",
    "        percentile_dict = {}\n",
    "        \n",
    "        for col in columns:\n",
    "          #Looping through each row of the dataframe\n",
    "          for index, row in df_file.iterrows():\n",
    "            row_date = row[dayofcentury]\n",
    "            if row_date == day_century and ~ np.isnan(row[col]):\n",
    "              # Retrieving Value \n",
    "              value = row[col]\n",
    "              # Excluding NAN's for the calculation\n",
    "              col_list = df_file[col].dropna().values.tolist()\n",
    "              # Calculate the Percentiles\n",
    "              percentile = stats.percentileofscore(col_list,value)\n",
    "              #Count the number of values \n",
    "              count = len(col_list)\n",
    "              # Assign file, value and, percentile to dictionary\n",
    "              percentile_dict[col] = row[col]\n",
    "              percentile_dict[f\"{col}_pcte\"] = percentile\n",
    "              percentile_dict[f\"{col}_n\"] = count\n",
    "              \n",
    "        percentile_dict[\"Station\"] = file\n",
    "\n",
    "          #Add the percentile dictionary to the list\n",
    "        percentiles.append({'Station': file,**percentile_dict})\n",
    "    \n",
    "    print(\"Finished Calculating Percentiles\")\n",
    "    \n",
    "    #Create a dataframe from the list of dictionaries\n",
    "    percentiles_df = pd.DataFrame(percentiles)\n",
    "\n",
    "    print(\"Transforming Output...\")\n",
    "    return percentiles_df\n",
    "\n",
    "def _transform_percentiles(percentiles_df):\n",
    "    \n",
    "    # Define a list of all the columns in the original dataframe\n",
    "    columns_list = percentiles_df.columns\n",
    "    # Split the list into two parts based on which columns have '_pcte' and '_n' in the name\n",
    "    century_list = [i for i in columns_list if '_pcte' in i]\n",
    "    number_list = [i for i in columns_list if '_n' in i]\n",
    "    # Select the columns which do not have '_pcte' and '_n'\n",
    "    value_list = [i for i in columns_list if i not in century_list and i not in number_list and i not in \"Station\"] \n",
    "    # Build the new dataframe from the lists\n",
    "    transformed_df = pd.DataFrame(columns=['Station', 'Variable', 'Percentile', 'Number of Comparison Values', 'Original Values'])\n",
    "    # Loop through each entry in the original dataframe\n",
    "    for row in percentiles_df.iterrows():\n",
    "        # Take the Station value and loop through all of the remaining values\n",
    "        station_val = row[1]['Station']\n",
    "        for value, century, number in zip(value_list, century_list, number_list):\n",
    "            # Create a new entry for the transformed_df\n",
    "            new_entry = [station_val, value, row[1][century], row[1][number], row[1][value]]\n",
    "            transformed_df.loc[len(transformed_df)] = new_entry\n",
    "     \n",
    "    # Filter out extreme values       \n",
    "    transformed_df = transformed_df[(transformed_df[\"Percentile\"] > 90) | (transformed_df[\"Percentile\"] < 10)].reset_index()\n",
    "    \n",
    "    return transformed_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqiI9vb8I1ID"
   },
   "source": [
    "**Report Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ZSEjn5zDJMYZ"
   },
   "outputs": [],
   "source": [
    "def get_data(data, measurement, aws, date = datetime.datetime.today().strftime('%Y-%m-%d') \n",
    "                   ,scope = \"Relative\", output = \"Report\"):\n",
    "    \"\"\"\n",
    "    Function to return the underlying dataset of specified values given a selected date.\n",
    "    \n",
    "    Parameters:\n",
    "    data (str): The dataset to be used.\n",
    "    date (str): The date of the observations for which the percentile is calculated.\n",
    "    aws (str): The automatic weather station.\n",
    "    measurement (str): The measurement. \n",
    "    scope (str): Relative: values are compared to historical values of the day of year. \n",
    "                 Absolute: values are compared to historical values.\n",
    "\n",
    "    output (str): Output as pd.df or as printed report. \n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Data\n",
    "    df = _load_data(data)\n",
    "    \n",
    "    # Align GC Net & PROMICE Columns  \n",
    "    station, datetime, dayofcentury, dayofyear = _align_GC_PR()\n",
    "    \n",
    "    # Subset Data (date, measurement, station)\n",
    "    day, df,columns, day_century, unique_files = _subset_df(date,df, station, datetime, measurement, dayofcentury, dayofyear, aws)\n",
    "    \n",
    "    # Subset Data (Scope)\n",
    "    df = _subset_scope(scope, df, day, dayofyear)\n",
    "\n",
    "    ##### Output #######\n",
    "    if output == \"Report\":\n",
    "        from tabulate import tabulate\n",
    "        #### Report OUTPUT ###########\n",
    "        print(\n",
    "          f\"  Selected Date: {date} \\n\" ,\n",
    "          f\"Selected Station: {aws} \\n\" , \n",
    "          f\"Selected Measurement: {measurement} \\n\"  , \n",
    "          f\"Selected Data: {data} \\n\" ,\n",
    "          f\"Selected Scope: {scope} \\n\" ,\n",
    "          \"----------------------------------------------------------------------------------------------------------------------\\n\",\n",
    "          f\"                   Climatology Report\\n\" \n",
    "          )        \n",
    "        print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "       \n",
    "   \n",
    "    elif output == \"Data\":\n",
    "        return df\n",
    "    else: \n",
    "        raise ValueError(\"The input for the variable 'output' was not recognizable. Please use one of the following options: 'Report', 'Data'\" )\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "muRqsWyVVASH"
   },
   "outputs": [],
   "source": [
    "def daily_report(data, date = datetime.datetime.today().strftime('%Y-%m-%d'), \n",
    "                 aws = \"All\", measurement = \"All\", scope = \"Relative\", output = \"Report\", aggregated = False):\n",
    "    \"\"\"\n",
    "    Function to return the percentile of specified values given a selected date.\n",
    "    \n",
    "    Parameters:\n",
    "    data (str): The dataset to be used.\n",
    "    date (str): The date of the observations for which the percentile is calculated.\n",
    "    aws (str): The automatic weather station.\n",
    "    measurement (str): The measurement. \n",
    "    scope (str): Relative: values are compared to historical values of the day of year. \n",
    "                 Absolute: values are compared to historical values.\n",
    "    aggregated (bool): False: output is not aggregated.\n",
    "                       True: averages of stations are calculated.\n",
    "\n",
    "    output (str): Output as pd.df or as printed report. \n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Data\n",
    "    df = _load_data(data)\n",
    "    \n",
    "    # Align GC Net & PROMICE Columns  \n",
    "    station, datetime, dayofcentury, dayofyear = _align_GC_PR()\n",
    " \n",
    "    #Account for Aggregate variable\n",
    "    if aggregated == False:\n",
    "        df = df\n",
    "    elif aggregated == True:\n",
    "        # Group df by station \n",
    "        df = df ##### TBD #######\n",
    "    else: \n",
    "        raise ValueError(f\"The input for the variable 'aggregated' was not recognizable. Please use one of the following options: True, False\")\n",
    "\n",
    "    # Subset Data (date, measurement, station)\n",
    "    #day, df = _subset_df(date,df, station, datetime, measurement, dayofcentury, dayofyear, aws)\n",
    "    day, df,columns, day_century, unique_files = _subset_df(date, df, station, datetime, measurement, dayofcentury, dayofyear, aws)\n",
    "    \n",
    "    # Subset Data (Scope)\n",
    "    df = _subset_scope(scope, df, day, dayofyear)\n",
    "    \n",
    "    # Calculate Percentiles\n",
    "    percentiles_df = _percentiles(df, unique_files, station, columns, dayofcentury, day_century)\n",
    "  \n",
    "    # Transform Output\n",
    "    transformed_df = _transform_percentiles(percentiles_df)\n",
    "    \n",
    "    print(\"Finished\")\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "   # print(tabulate(percentiles_df, headers='keys', tablefmt='psql'))\n",
    "   # return percentiles_df\n",
    "    if output == \"Report\":\n",
    "        from tabulate import tabulate\n",
    "        #### Report OUTPUT ###########\n",
    "        print(\n",
    "          f\"  Selected Date: {date} \\n\" ,\n",
    "          f\"Selected Station: {aws} \\n\" , \n",
    "          f\"Selected Measurement: {measurement} \\n\"  , \n",
    "          f\"Selected Data: {data} \\n\" ,\n",
    "          f\"Selected Scope: {scope} \\n\" ,\n",
    "          \"----------------------------------------------------------------------------------------------------------------------\\n\",\n",
    "          f\"                   Climatology Report\\n\" \n",
    "          )        \n",
    "        print(tabulate(transformed_df, headers='keys', tablefmt='psql'))\n",
    "       \n",
    "        input_ = input(\"Do you want to include graphics? (Y/N)\")\n",
    "        if input_ == \"Y\":\n",
    "          ########## TBD: Replace with boxplot function #################\n",
    "          print(\"Functionality is in development\")\n",
    "   \n",
    "    elif output == \"Data\":\n",
    "        return transformed_df\n",
    "    else: \n",
    "        raise ValueError(\"The input for the variable 'output' was not recognizable. Please use one of the following options: 'Report', 'Data'\" )\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a_PCDX9qbKdO",
    "outputId": "064050ab-0609-46db-9583-f3b3085dd7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Percentiles .... \n",
      "Finished Calculating Percentiles\n",
      "Transforming Output...\n",
      "Finished\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Station</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>Number of Comparison Values</th>\n",
       "      <th>Original Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>relative_humidity_1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>95.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>relative_humidity_1_cor</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>112.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>relative_humidity_2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>97.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>relative_humidity_2_cor</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>114.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>shortwave_outgoing_radiation</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_10</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-7.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_6</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_7</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>49</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>snow_temperature_8</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>wind_speed_1</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55</td>\n",
       "      <td>Swiss Camp</td>\n",
       "      <td>wind_speed_2</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>231</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>air_temperature_1</td>\n",
       "      <td>95.454545</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-30.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>232</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>air_temperature_2</td>\n",
       "      <td>95.454545</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-30.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>235</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>relative_humidity_1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>236</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>relative_humidity_1_cor</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>237</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>relative_humidity_2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>72.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>238</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>relative_humidity_2_cor</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>97.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>253</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>wind_speed_2</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>254</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>air_pressure</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>23.0</td>\n",
       "      <td>752.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>256</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>specific_humidity_1</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>257</td>\n",
       "      <td>Tunu-N</td>\n",
       "      <td>specific_humidity_2</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>267</td>\n",
       "      <td>DYE2</td>\n",
       "      <td>net_radiation</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>272</td>\n",
       "      <td>DYE2</td>\n",
       "      <td>shortwave_incoming_radiation</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>273</td>\n",
       "      <td>DYE2</td>\n",
       "      <td>shortwave_outgoing_radiation</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>274</td>\n",
       "      <td>DYE2</td>\n",
       "      <td>snow_depth_1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>406</td>\n",
       "      <td>NASA-E</td>\n",
       "      <td>snow_depth_1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>424</td>\n",
       "      <td>NASA-E</td>\n",
       "      <td>snow_depth_2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>426</td>\n",
       "      <td>NASA-E</td>\n",
       "      <td>snow_temperature_1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-28.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>427</td>\n",
       "      <td>NASA-E</td>\n",
       "      <td>snow_temperature_2</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-28.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>428</td>\n",
       "      <td>NASA-E</td>\n",
       "      <td>snow_temperature_3</td>\n",
       "      <td>91.304348</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-28.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     Station                      Variable  Percentile  \\\n",
       "0      37  Swiss Camp           relative_humidity_1  100.000000   \n",
       "1      38  Swiss Camp       relative_humidity_1_cor  100.000000   \n",
       "2      39  Swiss Camp           relative_humidity_2  100.000000   \n",
       "3      40  Swiss Camp       relative_humidity_2_cor  100.000000   \n",
       "4      42  Swiss Camp  shortwave_outgoing_radiation  100.000000   \n",
       "5      44  Swiss Camp           snow_temperature_10   94.444444   \n",
       "6      45  Swiss Camp            snow_temperature_4  100.000000   \n",
       "7      46  Swiss Camp            snow_temperature_5  100.000000   \n",
       "8      47  Swiss Camp            snow_temperature_6   94.444444   \n",
       "9      48  Swiss Camp            snow_temperature_7   94.117647   \n",
       "10     49  Swiss Camp            snow_temperature_8  100.000000   \n",
       "11     54  Swiss Camp                  wind_speed_1    5.555556   \n",
       "12     55  Swiss Camp                  wind_speed_2    5.263158   \n",
       "13    231      Tunu-N             air_temperature_1   95.454545   \n",
       "14    232      Tunu-N             air_temperature_2   95.454545   \n",
       "15    235      Tunu-N           relative_humidity_1  100.000000   \n",
       "16    236      Tunu-N       relative_humidity_1_cor  100.000000   \n",
       "17    237      Tunu-N           relative_humidity_2  100.000000   \n",
       "18    238      Tunu-N       relative_humidity_2_cor  100.000000   \n",
       "19    253      Tunu-N                  wind_speed_2    4.347826   \n",
       "20    254      Tunu-N                  air_pressure    8.695652   \n",
       "21    256      Tunu-N           specific_humidity_1   95.000000   \n",
       "22    257      Tunu-N           specific_humidity_2   95.000000   \n",
       "23    267        DYE2                 net_radiation  100.000000   \n",
       "24    272        DYE2  shortwave_incoming_radiation    8.695652   \n",
       "25    273        DYE2  shortwave_outgoing_radiation    8.695652   \n",
       "26    274        DYE2                  snow_depth_1  100.000000   \n",
       "27    406      NASA-E                  snow_depth_1  100.000000   \n",
       "28    424      NASA-E                  snow_depth_2  100.000000   \n",
       "29    426      NASA-E            snow_temperature_1  100.000000   \n",
       "30    427      NASA-E            snow_temperature_2   97.500000   \n",
       "31    428      NASA-E            snow_temperature_3   91.304348   \n",
       "\n",
       "    Number of Comparison Values  Original Values  \n",
       "0                          18.0            95.29  \n",
       "1                          18.0           112.84  \n",
       "2                          17.0            97.16  \n",
       "3                          17.0           114.99  \n",
       "4                          19.0             0.82  \n",
       "5                          18.0            -7.48  \n",
       "6                          17.0            -4.54  \n",
       "7                          16.0            -4.73  \n",
       "8                          18.0            -5.00  \n",
       "9                          17.0            -5.41  \n",
       "10                         16.0            -4.44  \n",
       "11                         18.0             3.58  \n",
       "12                         19.0             3.88  \n",
       "13                         22.0           -30.92  \n",
       "14                         22.0           -30.61  \n",
       "15                         20.0            72.81  \n",
       "16                         20.0            98.32  \n",
       "17                         20.0            72.79  \n",
       "18                         20.0            97.99  \n",
       "19                         23.0             3.53  \n",
       "20                         23.0           752.17  \n",
       "21                         20.0             0.29  \n",
       "22                         20.0             0.30  \n",
       "23                         24.0             0.22  \n",
       "24                         23.0             1.28  \n",
       "25                         23.0             1.00  \n",
       "26                         23.0            16.17  \n",
       "27                         20.0             8.86  \n",
       "28                         20.0             8.27  \n",
       "29                         20.0           -28.94  \n",
       "30                         20.0           -28.89  \n",
       "31                         23.0           -28.83  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_report(data = \"GC Net\", date = \"2022-01-12\", measurement= \"All\", scope='Relative', aws=\"All\", output = \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4rWUVbYLgvJ",
    "outputId": "03b38cbf-aaf2-4631-85c6-b4d0ddc36099"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>relative_humidity_2_cor</th>\n",
       "      <th>DayOfCentury</th>\n",
       "      <th>DayOfYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122655</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>84.92</td>\n",
       "      <td>735122</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128861</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>80.48</td>\n",
       "      <td>735487</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135073</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>69.94</td>\n",
       "      <td>735852</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141279</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>83.40</td>\n",
       "      <td>736217</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147492</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>66.37</td>\n",
       "      <td>736582</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153204</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>80.66</td>\n",
       "      <td>736947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158162</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>86.69</td>\n",
       "      <td>737312</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162457</th>\n",
       "      <td>E-GRIP</td>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>78.22</td>\n",
       "      <td>737677</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file   Datetime  relative_humidity_2_cor  DayOfCentury  DayOfYear\n",
       "122655  E-GRIP 2015-01-12                    84.92        735122         12\n",
       "128861  E-GRIP 2016-01-12                    80.48        735487         12\n",
       "135073  E-GRIP 2017-01-12                    69.94        735852         12\n",
       "141279  E-GRIP 2018-01-12                    83.40        736217         12\n",
       "147492  E-GRIP 2019-01-12                    66.37        736582         12\n",
       "153204  E-GRIP 2020-01-12                    80.66        736947         12\n",
       "158162  E-GRIP 2021-01-12                    86.69        737312         12\n",
       "162457  E-GRIP 2022-01-12                    78.22        737677         12"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(data = \"GC Net\", date = \"2022-01-12\", measurement= \"relative_humidity_2_cor\", scope='Relative', output = \"Data\", aws=\"E-GRIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test Suite***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n94UQB81BF07"
   },
   "outputs": [],
   "source": [
    "def report(data, date, station, variable, scope):\n",
    "    \"\"\"\n",
    "    Function to return the percentile of specified values given a selected date.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe to be used.\n",
    "    date (str): The date of the observations for which the percentile is calculated.\n",
    "    \n",
    "    Returns:\n",
    "    df (pd.DataFrame): A dataframe with all numerical columns and the percentiles of the values of the selected date.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Ignore Warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "  \n",
    "    # Load data\n",
    "    if data == \"GC Net\":\n",
    "        df = pd.read_parquet('data\\df_daily.gzip', engine='pyarrow')\n",
    "    elif data == \"Promice\":\n",
    "        df = pd.read_parquet('data\\promice_daily.gzip', engine='pyarrow')\n",
    "    else: \n",
    "        raise ValueError(\"Only 'GC Net' & 'Promice' are accepted input values\")\n",
    "  \n",
    "    # Split date input into year, month, day\n",
    "    year = int(date[0:4])\n",
    "    month = int(date[5:7])\n",
    "    day = int(date[8:10])\n",
    "  \n",
    "    # subset df with date and find day of year and day variable\n",
    "    date_df = df.loc[(df['Datetime'].dt.year == year) & (df['Datetime'].dt.month == month) & (df['Datetime'].dt.day == day)]\n",
    "      # select day of year\n",
    "    day =  date_df[\"DayOfYear\"].mean()\n",
    "    datetime = date_df[\"Datetime\"].max()\n",
    "  \n",
    "    # select the specific day of century and the related values\n",
    "    day_century = date_df[\"DayOfCentury\"].mean() \n",
    "    day_century_value = pd.DataFrame(pd.DataFrame.mean(date_df)).reset_index()\n",
    "    day_century_value = pd.pivot_table(day_century_value, index=None, columns=['index'], aggfunc=max)\n",
    "  \n",
    "    if scope == \"relative\":\n",
    "        # group by calender day\n",
    "        df = df.loc[df['DayOfYear'] == day]\n",
    "    elif scope == \"absolute\":\n",
    "        df = df\n",
    "    else: \n",
    "        raise ValueError(\"Only 'relative' & 'absolute' are accepted input values\")\n",
    "  \n",
    "    # Find the index with the specified date\n",
    "    row_index = int(df[df['Datetime'] == date].index[0])\n",
    "    \n",
    "    # Remove columns that do not contain numerical values & Subset df based on measure selection\n",
    "    if variable == \"All\":\n",
    "        df = df.select_dtypes(include=['int', 'float']).copy()\n",
    "    else:\n",
    "        df = pd.DataFrame({variable: df[variable]})\n",
    "        df = df.select_dtypes(include=['int', 'float']).copy()\n",
    "    \n",
    "    # Create an empty dictionary for the output\n",
    "    percentile_dict = {}\n",
    "    \n",
    "    # Iterate through the columns\n",
    "    for col in df.columns:\n",
    "        # Find the percentile of the value in the specified row and date\n",
    "        value = df[col][row_index]\n",
    "        percentile = df[col].rank(pct=True)[df[col] == value].iloc[0]*100 if not math.isnan(value) else math.nan\n",
    "    \n",
    "        # Add the percentile to the dictionary\n",
    "        percentile_dict[col] = percentile\n",
    "    \n",
    "    # Create a dataframe with the output\n",
    "    x = pd.DataFrame(percentile_dict, index=[0])\n",
    "  \n",
    "    import prettytable as pt\n",
    "  \n",
    "    table = pt.PrettyTable()\n",
    "    table.field_names = [\"Measurement\", \"Percentile\"]\n",
    "  \n",
    "    for col in x.columns:\n",
    "        if x[col].values > 90 or x[col].values < 10:\n",
    "            table.add_row([f\"\\033[1m{col}\\033[0m\", f\"\\033[1m{int(x[col].values) if not np.isnan(x[col].values) else 'NaN'}%\\033[0m\"])\n",
    "        else:\n",
    "            table.add_row([col, f\"{int(x[col].values) if not np.isnan(x[col].values) else 'NaN'}%\"])\n",
    "  \n",
    "    print(\n",
    "    f\" Date: {date} \\n\" ,\n",
    "    f\"Station: {station} \\n\" , \n",
    "    f\"Measurement: {variable} \\n\"  , \n",
    "    f\"Data: {data} \\n\" ,\n",
    "    \"----------------------------------------------------------------------------------------------------------------------\\n\",\n",
    "    f\"                   Climatology Report\\n\" \n",
    "    )\n",
    "    print(table)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    import plotly.express as px\n",
    "    # Create a list of columns to be plotted\n",
    "    x = day_century_value\n",
    "    columns_to_plot = [col for col in x.columns.values if col in df.columns.values]\n",
    "  \n",
    "    # Create a list of values from x to be highlighted\n",
    "    values_to_highlight = x[columns_to_plot].values.flatten().tolist()\n",
    "  \n",
    "    # Create a list of subplots\n",
    "    figs = []\n",
    "    # Loop through list of columns\n",
    "    for col, v in zip(columns_to_plot, values_to_highlight) : \n",
    "        # Create a subplot for each column \n",
    "        fig = px.box(df[col], orientation = \"v\",boxmode='group')\n",
    "        # Format the axes\n",
    "        fig.update_layout(title_text= f\"Boxplot for {col}\", xaxis_title='', yaxis_title='')\n",
    "        # Highlight the values from x\n",
    "        fig.add_scatter(x=[col], y=[v], name= f\"Selected Value \\n{col}\",\n",
    "    mode = 'markers',\n",
    "    marker_symbol = 'circle-dot',\n",
    "    marker_size = 8,\n",
    "    marker_color = 'red')\n",
    "        \n",
    "        # Add figure to list of subplots \n",
    "        figs.append(fig)\n",
    "    \n",
    "    # Output\n",
    "    for fig in figs:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-tV92FHNcuy"
   },
   "outputs": [],
   "source": [
    "report(\"Promice\", \"2022-01-12\", \"THU_L_day_v03\", variable = \"All\", scope = \"relative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLqu3qB_6MQ0"
   },
   "source": [
    "GC Net Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fukMbLF5FSk"
   },
   "outputs": [],
   "source": [
    "gc = pd.read_parquet('data\\df_daily.gzip', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxF98U06Pr1K",
    "outputId": "d65d82bc-1300-4d26-d453-8ae01ea6a729"
   },
   "outputs": [],
   "source": [
    "gc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPzKcUQf-D8A"
   },
   "source": [
    "*Test on one station*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b43DzmSi5XuP"
   },
   "outputs": [],
   "source": [
    "gc = gc[gc['station_name'] == \"Humboldt\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zyy-tj5MR42i"
   },
   "source": [
    "Promice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX5FjdtC9_6o"
   },
   "outputs": [],
   "source": [
    "pc = pd.read_parquet('data\\promice_hourly.gzip', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "cSviVwGoTdRw",
    "outputId": "5c30dbcc-5116-4b8a-f4c2-1a4fe452765b"
   },
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgMPhvzQ-Jn-"
   },
   "source": [
    "*Test Suite*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QCsyeJ2Kjtz"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "\n",
    "# *Mandatory: Data\n",
    "data = \"Promice\"\n",
    "\n",
    "# *Mandatory: Date\n",
    "date = \"22-07-2008\"\n",
    "\n",
    "# Optional: Station\n",
    "#station = \"SCO_L_hour_v03\"\n",
    "station = \"THU_L_day_v03\"\n",
    "\n",
    "# Optional: Measure\n",
    "y = \"All\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JqXn1dJ_q06"
   },
   "outputs": [],
   "source": [
    "# subset dataframe \n",
    "pc = pc[pc['file'] == station] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aT8guAQZBSWB",
    "outputId": "ca3ab4a8-faa9-404c-b2fe-221bfac7ff74"
   },
   "outputs": [],
   "source": [
    "# select dato \n",
    "year= 2022\n",
    "month = 1\n",
    "day = 12\n",
    "\n",
    "# subset df with date and find day of year and day variable\n",
    "date_df = pc.loc[(pc['Datetime'].dt.year == year) & (pc['Datetime'].dt.month == month) & (pc['Datetime'].dt.day == day)]\n",
    "  # select day of year\n",
    "day =  date_df[\"DayOfYear\"].mean()\n",
    "datetime = date_df[\"Datetime\"].max()\n",
    "\n",
    "# select the specific day of century and the related values\n",
    "day_century = date_df[\"DayOfCentury\"].mean() \n",
    "day_century_value = pd.DataFrame(pd.DataFrame.mean(date_df)).reset_index()\n",
    "day_century_value = pd.pivot_table(day_century_value, index=None, columns=['index'], aggfunc=max)\n",
    "\n",
    "# group by calender day\n",
    "pc_group = pc.loc[pc['DayOfYear'] == day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRiwe8ApUBQg"
   },
   "outputs": [],
   "source": [
    "def get_percentile(df, date):\n",
    "  \"\"\"\n",
    "  Function to return the percentile of specified values given a selected date.\n",
    "  \n",
    "  Parameters:\n",
    "  df (pd.DataFrame): The dataframe to be used.\n",
    "  date (str): The date of the observations for which the percentile is calculated.\n",
    "  \n",
    "  Returns:\n",
    "  df (pd.DataFrame): A dataframe with all numerical columns and the percentiles of the values of the selected date.\n",
    "  \"\"\"\n",
    "\n",
    "  # Find the index with the specified date\n",
    "  row_index = int(df[df['Datetime'] == date].index[0])\n",
    "  \n",
    "  # Remove columns that do not contain numerical values & Subset df based on measure selection\n",
    "  if y == \"All\":\n",
    "    df = df.select_dtypes(include=['int', 'float']).copy()\n",
    "  else:\n",
    "    df = pd.DataFrame(df[y])\n",
    "    df = df.select_dtypes(include=['int', 'float']).copy()\n",
    "  \n",
    "  # Create an empty dictionary for the output\n",
    "  percentile_dict = {}\n",
    "  \n",
    "  # Iterate through the columns\n",
    "  for col in df.columns:\n",
    "    # Find the percentile of the value in the specified row and date\n",
    "    value = df[col][row_index]\n",
    "    if(math.isnan(value)): \n",
    "      percentile = math.nan\n",
    "    else: \n",
    "      # calculate the percentile with df.rank()\n",
    "      percentile = df[col].rank(pct=True)[df[col] == value].iloc[0]*100\n",
    "    \n",
    "    # Add the percentile to the dictionary\n",
    "    #percentile_dict[col + \"_percentile\"] = percentile\n",
    "    percentile_dict[col] = percentile\n",
    "  \n",
    "  \n",
    "  # Create a dataframe with the output\n",
    "  df_percentiles = pd.DataFrame(percentile_dict, index=[0])\n",
    "  return df_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDyUE1f3e0VI"
   },
   "outputs": [],
   "source": [
    "x = get_percentile(pc, \"2022-01-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuiTvk_qXU0x"
   },
   "outputs": [],
   "source": [
    "#x = x.append(day_century_value.iloc[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXCUB3RtC1og"
   },
   "outputs": [],
   "source": [
    "x = get_percentile(pc_group, \"2022-01-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdluROhkTwey"
   },
   "outputs": [],
   "source": [
    "import prettytable as pt\n",
    "\n",
    "table = pt.PrettyTable()\n",
    "table.field_names = [\"Measurement\", \"Percentile\"]\n",
    "\n",
    "for col in x.columns:\n",
    "    if x[col].values > 90 or x[col].values < 10:\n",
    "        table.add_row([f\"\\033[1m{col}\\033[0m\", f\"\\033[1m{int(x[col].values) if not np.isnan(x[col].values) else 'NaN'}% \\033[0m\"])\n",
    "    else:\n",
    "        table.add_row([col, f\"{int(x[col].values) if not np.isnan(x[col].values) else 'NaN'}%\"])\n",
    "\n",
    "\n",
    "print(\n",
    "f\" Date: {date} \\n\" ,\n",
    "f\"Station: {station} \\n\" , \n",
    "f\"Measurment: {y} \\n\"  , \n",
    "f\"Data: {data} \\n\" ,\n",
    "\"-----------------------------------------------------------\\n\",\n",
    "f\"                   Climatology \\n\" \n",
    ")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSL_YvCzM5WH"
   },
   "source": [
    "*Visual test suite*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwVbdIWlQzB3"
   },
   "outputs": [],
   "source": [
    "############################ Boxplots #########################################\n",
    "ff = pc \n",
    "x = ff.loc[ff['Datetime'] == \"2022-01-12\"]\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a list of columns to be plotted\n",
    "columns_to_plot = [col for col in x.columns.values if col in ff.columns.values]\n",
    "\n",
    "# Create a list of values from x to be highlighted\n",
    "values_to_highlight = x[columns_to_plot].values.flatten().tolist()\n",
    "\n",
    "# Create a list of subplots\n",
    "figs = []\n",
    "# Loop through list of columns\n",
    "for col, v in zip(columns_to_plot,values_to_highlight) : \n",
    "  # Create a subplot for each column \n",
    "  fig = px.box(ff[col], orientation = \"v\",boxmode='group')\n",
    "  # Format the axes\n",
    "  fig.update_layout(title_text= f\"Boxplot for {col}\", xaxis_title='', yaxis_title='')\n",
    "  # Highlight the values from x\n",
    "  fig.add_scatter(x=[col], y=[v], name= f\"Selected Value \\n{col}\",\n",
    "                        mode = 'markers',\n",
    "                        marker_symbol = 'circle-dot',\n",
    "                        marker_size = 8,\n",
    "                        marker_color = 'red')\n",
    "  \n",
    "  # Add figure to list of subplots \n",
    "  figs.append(fig)\n",
    "\n",
    "# Show the plots\n",
    "for fig in figs:\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDnpp8IWP7et"
   },
   "outputs": [],
   "source": [
    "# A function that calculates the percentiles of every column and their values\n",
    "\n",
    "def percentile_df(df):\n",
    "    for col in (df.columns):\n",
    "        df[f'{col}_pcta'] = df[col].rank(pct=True)\n",
    "        #df[f'{col}_pcta'] = df[col].rank(pct=True)[df[col] == value] *100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpaD_Cs8QGBN"
   },
   "outputs": [],
   "source": [
    "gg = percentile_df(pc)\n",
    "gg = gg[[\"Datetime\", \"AirTemperature(C)\", \"AirTemperature(C)_pcta\"]]\n",
    "y = \"AirTemperature(C)\"\n",
    "y_pcta = \"AirTemperature(C)_pcta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "iKnFra5QoDVG",
    "outputId": "3a39e8ff-950a-4bd4-f520-ab000ec7d0b1"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        name='Air Pressure (hPa)',\n",
    "        x=gg['Datetime'],\n",
    "        y=gg[y],\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(31, 119, 180)'),\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Upper Bound (20-80)',\n",
    "        x=gg['Datetime'],\n",
    "        y=(gg[y] * (gg[y_pcta])),\n",
    "        mode='lines',\n",
    "        marker=dict(color=\"#00BB00\"),\n",
    "        line=dict(width=0),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Lower Bound (20-80)',\n",
    "        x=gg['Datetime'],\n",
    "        y=(gg[y] * (gg[y_pcta])),\n",
    "        marker=dict(color=\"#00BB00\"),\n",
    "        line=dict(width=0),\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(0, 187, 0, 0.3)',\n",
    "        fill='tonexty',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Upper Bound (0-20 & 80-100)',\n",
    "        x=gg['Datetime'],\n",
    "        y=(gg[y] * (gg[y_pcta]  )),\n",
    "        mode='lines',\n",
    "        marker=dict(color=\"#BB0000\"),\n",
    "        line=dict(width=0),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Lower Bound (0-20 & 80-100)',\n",
    "        x=gg['Datetime'],\n",
    "        y=(gg[y] * (gg[y_pcta] )),\n",
    "        marker=dict(color=\"#BB0000\"),\n",
    "        line=dict(width=0),\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(187, 0, 0, 0.3)',\n",
    "        fill='tonexty',\n",
    "        showlegend=False\n",
    "    )\n",
    "])\n",
    "fig.update_layout(\n",
    "    yaxis_title='Air Pressure (hPa)',\n",
    "    title='Continuous, variable value error bars',\n",
    "    hovermode=\"x\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcfAwtxhsaIx"
   },
   "outputs": [],
   "source": [
    "gg.loc[(gg['Datetime'].dt.month == 12) & (gg['Datetime'].dt.day == 31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkFAcDF_soHP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
