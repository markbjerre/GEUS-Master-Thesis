{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLqu3qB_6MQ0"
   },
   "source": [
    "GC Net Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from pyarrow) (1.24.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/Users/nilsfulde/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "iFn7hTObSpj6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/GEUS-PROMICE/pyNEAD.git\n",
      "  Cloning https://github.com/GEUS-PROMICE/pyNEAD.git to /private/var/folders/_r/2f7t_cz14232jqp3576_p04m0000gn/T/pip-req-build-lq7_zv60\n",
      "  Running command git clone --filter=blob:none -q https://github.com/GEUS-PROMICE/pyNEAD.git /private/var/folders/_r/2f7t_cz14232jqp3576_p04m0000gn/T/pip-req-build-lq7_zv60\n",
      "  Resolved https://github.com/GEUS-PROMICE/pyNEAD.git to commit d811220c2d048d84d4612b045880d6ca914c39a4\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from nead==0.0.0) (1.24.2)\n",
      "Requirement already satisfied: pandas in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from nead==0.0.0) (1.5.3)\n",
      "Requirement already satisfied: xarray in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from nead==0.0.0) (2023.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from pandas->nead==0.0.0) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from pandas->nead==0.0.0) (2.8.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from xarray->nead==0.0.0) (23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nilsfulde/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->nead==0.0.0) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/Users/nilsfulde/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/GEUS-PROMICE/pyNEAD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba5Hy-lHR2Jr",
    "outputId": "22868e77-0da1-4934-9b33-e66e47e507c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nilsfulde/Documents/University/University/CPH/Master/2_Semester/Machine_Learning/Exam/FairFace/GEUS-Master-Thesis\n",
      "Overwritting existing data in \"/data\"\n",
      "Downloading daily data...\r\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env bash\n",
    "\n",
    "# Latest L1 data: https://github.com/GEUS-Glaciology-and-Climate/GC-Net-level-1-data-processing/tree/main/L1\n",
    "# API contents of latest L1 data (raw URLs etc.): https://api.github.com/repositories/319306521/contents/L1\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\nifu18ab\\\\Desktop\\\\GEUS-Master-Thesis')\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"data\")\n",
    "    os.mkdir(\"data/data_daily\")\n",
    "    os.mkdir(\"data/data_hourly\")\n",
    "except:\n",
    "    print('Overwritting existing data in \"/data\"')\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# Download data\n",
    "print(\"Downloading daily data...\\r\")\n",
    "\n",
    "\n",
    "# xargs -n 1 curl --silent -O --output-dir data_daily < ../metadata/urls_1.txt\n",
    "for url in open(\"metadata/urls_1.txt\"):\n",
    "    # Split on the rightmost / and take everything on the right side of that\n",
    "    name = url.rsplit(\"/\", 1)[-1].replace(\"\\r\", \"\")\n",
    "    # Strip /n at the end of filename\n",
    "    name = name.strip()\n",
    "    # Combine the name and the downloads directory to get the local filename\n",
    "    filename = os.path.join(\"data/data_daily\", name)\n",
    "\n",
    "    # Download the file if it does not exist\n",
    "    if not os.path.isfile(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exKNv5IVbMx-",
    "outputId": "3f0f0b01-578c-4d40-940c-ecfd2547209b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hourly data...\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading hourly data...\\r\")\n",
    "# xargs -n 1 curl --silent -O --output-dir data_hourly < ../metadata/urls_2.txt\n",
    "for url in open(\"metadata/urls_2.txt\"):\n",
    "    # Split on the rightmost / and take everything on the right side of that\n",
    "    name = url.rsplit(\"/\", 1)[-1].replace(\"\\r\", \"\")\n",
    "    # Strip /n at the end of filename\n",
    "    name = name.strip()\n",
    "    # Combine the name and the downloads directory to get the local filename\n",
    "    filename = os.path.join(\"data/data_hourly\", name)\n",
    "\n",
    "    # Download the file if it does not exist\n",
    "    if not os.path.isfile(filename):\n",
    "        urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QqbmK6FqeRkP"
   },
   "outputs": [],
   "source": [
    "# Process data\n",
    "# echo -ne 'Processing dairly data...\\r'\n",
    "# python scripts/process_data_daily.py\n",
    "# echo -ne 'Processing hourly data...\\r'\n",
    "# python scripts/process_data_hourly.py\n",
    "\n",
    "# Delete unprocessed data\n",
    "# rm -r data_daily data_hourly\n",
    "\n",
    "# %% process data daily\n",
    "import pandas as pd\n",
    "import nead\n",
    "\n",
    "# Convert NEAD files to Pandas dataframes\n",
    "station = pd.read_csv(\"metadata/station_info.csv\", header=0)\n",
    "dfs_daily = []\n",
    "\n",
    "for name, ID in zip(station.Name, station.ID):\n",
    "    format_name = name.replace(\" \", \"\")\n",
    "    files = \"data/data_daily/\" + str(ID).zfill(2) + \"-\" + format_name + \"_daily.csv\"\n",
    "    ds_daily = nead.read(files, index_col=0)\n",
    "    df_daily = ds_daily.to_dataframe()\n",
    "    df_daily.insert(\n",
    "        loc=0, column=\"station_name\", value=name\n",
    "    )  # Add station_name column to each dataframe\n",
    "    dfs_daily.append(df_daily)\n",
    "\n",
    "# Concatenate dataframes\n",
    "df_daily = pd.concat(dfs_daily).sort_index()\n",
    "\n",
    "# Delete irrelevant columns from dataframe (i.e. null columns and flag columns)\n",
    "# null_columns = df_daily.columns[df_daily.isnull().all()]\n",
    "# flag_columns = df_daily.filter(regex=\"flag$\").columns\n",
    "# print(null_columns)\n",
    "# print(flag_columns)\n",
    "\n",
    "df_daily = df_daily.drop(\n",
    "    columns=[\n",
    "        \"OSWR_max\",\n",
    "        \"HW2_adj_flag\",\n",
    "        \"P_adj_flag\",\n",
    "        \"HW1_adj_flag\",\n",
    "        \"OSWR_adj_flag\",\n",
    "        \"HS1_adj_flag\",\n",
    "        \"HS2_adj_flag\",\n",
    "        \"TA3_adj_flag\",\n",
    "        \"TA4_adj_flag\",\n",
    "        \"DW1_adj_flag\",\n",
    "    ]\n",
    ")\n",
    "# Add season column to dataframe\n",
    "seasons = {\n",
    "    1: \"Winter\",\n",
    "    2: \"Winter\",\n",
    "    3: \"Spring\",\n",
    "    4: \"Spring\",\n",
    "    5: \"Spring\",\n",
    "    6: \"Summer\",\n",
    "    7: \"Summer\",\n",
    "    8: \"Summer\",\n",
    "    9: \"Autumn\",\n",
    "    10: \"Autumn\",\n",
    "    11: \"Autumn\",\n",
    "    12: \"Winter\",\n",
    "}\n",
    "\n",
    "# Extract the month from the index and use the dictionary to map it to the corresponding season\n",
    "df_daily[\"season\"] = df_daily.index.month.map(seasons)\n",
    "\n",
    "# Add year column to dataframe\n",
    "df_daily[\"year\"] = df_daily.index.strftime(\"%Y\")\n",
    "\n",
    "# Add month column to dataframe\n",
    "df_daily[\"month\"] = df_daily.index.strftime(\"%B\")\n",
    "\n",
    "# Rename Index Column to Datetime\n",
    "df_daily = df_daily.reset_index(inplace=False)\n",
    "df_daily = df_daily.rename(columns={'timestamp': 'Datetime'}, inplace=False) \n",
    "\n",
    "# Rename 'station_name' to file\n",
    "df_daily = df_daily.rename(columns={'station_name': 'file'}, inplace=False)\n",
    "\n",
    "# Add Day of Year & Day of Century \n",
    "df_daily['DayOfYear'] = df_daily['Datetime'].dt.dayofyear \n",
    "df_daily['DayOfCentury'] = df_daily['Datetime'].dt.dayofyear+365*(df_daily['Datetime'].dt.year-1)\n",
    "\n",
    "\n",
    "# # Add day column to dataframe\n",
    "# df_daily[\"day\"] = df_daily.index.strftime(\"%d\")\n",
    "\n",
    "# Add hour column to dataframe\n",
    "# df_daily[\"hour\"] = df_daily.index.strftime(\"%h\")\n",
    "\n",
    "# Change column headers\n",
    "#header = pd.read_csv('/content/drive/MyDrive/Master_Thesis/metadata/Masterdata_GCNET.csv', sep = \";\")\n",
    "header = pd.read_csv('metadata/Masterdata_GCNET.csv', sep = \";\")\n",
    "df_daily = df_daily.rename(columns = header.set_index('fields')['display_description'])\n",
    "\n",
    "# Save dataframe as parquet file\n",
    "df_daily.to_parquet(\"data/df_daily.gzip\", compression=\"gzip\", engine='pyarrow')\n",
    "\n",
    "# %% process data hourly\n",
    "# Convert NEAD files to Pandas dataframes\n",
    "station = pd.read_csv(\"metadata/station_info.csv\", header=0)\n",
    "dfs_hourly = []\n",
    "\n",
    "for name, ID in zip(station.Name, station.ID):\n",
    "    format_name = name.replace(\" \", \"\")\n",
    "    files = \"data/data_hourly/\" + str(ID).zfill(2) + \"-\" + format_name + \".csv\"\n",
    "    ds_hourly = nead.read(files, index_col=0)\n",
    "    df_hourly = ds_hourly.to_dataframe()\n",
    "    df_hourly.insert(\n",
    "        loc=0, column=\"station_name\", value=name\n",
    "    )  # Add station_name column to each dataframe\n",
    "    dfs_hourly.append(df_hourly)\n",
    "\n",
    "# Concatenate dataframes\n",
    "df_hourly = pd.concat(dfs_hourly).sort_index()\n",
    "\n",
    "# Delete irrelevant columns from dataframe (i.e. null columns and flag columns)\n",
    "# null_columns = df_hourly.columns[df_hourly.isnull().all()]\n",
    "# flag_columns = df_hourly.filter(regex=\"flag$\").columns\n",
    "# print(null_columns)\n",
    "# print(flag_columns)\n",
    "\n",
    "df_hourly = df_hourly.drop(\n",
    "    columns=[\n",
    "        \"OSWR_max\",\n",
    "        \"HW2_adj_flag\",\n",
    "        \"P_adj_flag\",\n",
    "        \"HW1_adj_flag\",\n",
    "        \"OSWR_adj_flag\",\n",
    "        \"HS1_adj_flag\",\n",
    "        \"HS2_adj_flag\",\n",
    "        \"TA3_adj_flag\",\n",
    "        \"TA4_adj_flag\",\n",
    "        \"DW1_adj_flag\",\n",
    "    ]\n",
    ")\n",
    "# Add year column to dataframe\n",
    "df_hourly[\"year\"] = df_hourly.index.strftime(\"%Y\")\n",
    "\n",
    "# Add month column to dataframe\n",
    "df_hourly[\"month\"] = df_hourly.index.strftime(\"%B\")\n",
    "\n",
    "# Add season column to dataframe\n",
    "seasons = {\n",
    "    1: \"Winter\",\n",
    "    2: \"Winter\",\n",
    "    3: \"Spring\",\n",
    "    4: \"Spring\",\n",
    "    5: \"Spring\",\n",
    "    6: \"Summer\",\n",
    "    7: \"Summer\",\n",
    "    8: \"Summer\",\n",
    "    9: \"Autumn\",\n",
    "    10: \"Autumn\",\n",
    "    11: \"Autumn\",\n",
    "    12: \"Winter\",\n",
    "}\n",
    "\n",
    "# Extract the month from the index and use the dictionary to map it to the corresponding season\n",
    "df_hourly[\"season\"] = df_hourly.index.month.map(seasons)\n",
    "\n",
    "\n",
    "#Rename Index Column to Datetime\n",
    "df_hourly = df_hourly.reset_index(inplace=False)\n",
    "df_hourly = df_hourly.rename(columns={'timestamp': 'Datetime'}, inplace=False) \n",
    "\n",
    "# Rename 'station_name' to file\n",
    "df_hourly = df_hourly.rename(columns={'station_name': 'file'}, inplace=False)\n",
    "\n",
    "# Add Day of Year & Day of Century \n",
    "df_hourly['DayOfYear'] = df_hourly['Datetime'].dt.dayofyear \n",
    "df_hourly['DayOfCentury'] = df_hourly['Datetime'].dt.dayofyear+365*(df_hourly['Datetime'].dt.year-1)\n",
    "\n",
    "\n",
    "# # Add day column to dataframe\n",
    "# df_hourly[\"day\"] = df_hourly.index.strftime(\"%d\")\n",
    "\n",
    "# # Add hour column to dataframe\n",
    "# df_hourly[\"hour\"] = df_hourly.index.strftime(\"%h\")\n",
    "\n",
    "\n",
    "#header = pd.read_csv('/content/drive/MyDrive/Master_Thesis/metadata/Masterdata_GCNET.csv', sep = \";\")\n",
    "header = pd.read_csv('metadata/Masterdata_GCNET.csv', sep = \";\")\n",
    "df_hourly = df_hourly.rename(columns = header.set_index('fields')['display_description'])\n",
    "\n",
    "# Save dataframe as parquet file\n",
    "df_hourly.to_parquet(\"data/df_hourly.gzip\", compression=\"gzip\", engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Promice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_csv_files(csv_directory=\"..\\..\\PROMICE-AWS-toolbox\\out\\L4\"):\n",
    "    \n",
    "    # List all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(csv_directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Combine all CSV files into a single DataFrame\n",
    "    dfs = []\n",
    "    for f in csv_files:\n",
    "        df = pd.read_csv(os.path.join(csv_directory, f), index_col=False)\n",
    "        df.insert(0, 'stid', f[:-7])\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    #read metadata from promice repository\n",
    "    station = pd.read_csv('..\\..\\PROMICE-AWS-toolbox\\metadata\\AWS_station_locations.csv', index_col=False)\n",
    "    station.to_csv('..\\\\data\\\\new_promice\\\\AWS_station_locations.csv', index=False)\n",
    "\n",
    "    output_file = \"..\\\\Data\\\\new_promice\\\\all_promice_data_hourly.parquet.gzip\"\n",
    "    df.to_parquet(output_file, compression='gzip', engine='pyarrow')\n",
    "\n",
    "    #display(output station and columns summary)\n",
    "    print('Stations loaded:')\n",
    "    display(df['stid'].unique())\n",
    "    print('columns in dataset:')\n",
    "    print(list(df.columns))\n",
    "    print(\"FINISHED LOADING CSV's\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_hourly_data(dataframe, directory=\"../data/new_promice/all_promice_data.parquet.gzip\", add_meta_data=False):\n",
    "\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        df_hourly = pd.read_parquet(directory)\n",
    "    else:\n",
    "        df_hourly = dataframe.copy()\n",
    "\n",
    "    # Add year column to dataframe\n",
    "    df_hourly[\"Datetime\"] = pd.to_datetime(df_hourly.time)\n",
    "\n",
    "    #Rename Index Column to Datetime\n",
    "    df_hourly = df_hourly.reset_index(inplace=False)\n",
    "\n",
    "    if add_meta_data==True:\n",
    "        add_nice_to_haves(df_hourly, 'hourly')\n",
    "\n",
    "    #display(df_hourly.head(10))\n",
    "\n",
    "    # Convert the DataFrame to a compressed Parquet file\n",
    "    output_file = \"../data/new_promice/all_promice_data_hourly.parquet.gzip\"\n",
    "    df_hourly.to_parquet(output_file, compression='gzip', engine='pyarrow')\n",
    "\n",
    "    print(\"FINISHED PROCESSING HOURLY DATA\")\n",
    "    return df_hourly\n",
    "\n",
    "def process_daily_data(dataframe=None, directory=\"\", add_meta_data=False):\n",
    "    \n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        dataframe = pd.read_parquet(directory)\n",
    "    else:\n",
    "        df = dataframe.copy()\n",
    "\n",
    "    # Define the date column that you want to group by (replace \"date_column\" with the name of your column)\n",
    "    min_values_per_day = 20\n",
    "\n",
    "    # Group the data by weather station and date\n",
    "    grouped = df.groupby(['stid','date'])\n",
    "\n",
    "    # Specify columns containing numerical values to be averaged\n",
    "    columns_to_average = (df\n",
    "                .select_dtypes(exclude=['object'])\n",
    "                .drop(columns=['index', 'Datetime', 'DayOfYear', 'DayOfCentury'])\n",
    "                .columns\n",
    "    )\n",
    "    # Calculate the number of non-NaN values for each variable within each group\n",
    "    valid_date_observations = grouped[columns_to_average].apply(lambda x: x.notna().sum() <= min_values_per_day)\n",
    "\n",
    "    # Calculate average per day per station\n",
    "    df_filtered = grouped[columns_to_average].mean()\n",
    "\n",
    "    #Remove means with less than 20 observations per day\n",
    "    df_masked = df_filtered.mask(valid_date_observations, np.nan)\n",
    "\n",
    "    df_daily = df_masked.reset_index().copy()\n",
    "\n",
    "    df_daily[\"Datetime\"] = pd.to_datetime(df_daily['date'])\n",
    "\n",
    "    if add_meta_data==True:\n",
    "        df_daily = add_nice_to_haves(df_daily, 'daily')\n",
    "\n",
    "    # Convert the DataFrame to a compressed Parquet file\n",
    "    output_file = \"..\\\\Data\\\\new_promice\\\\all_promice_data_daily.parquet.gzip\"\n",
    "    df_daily.to_parquet(output_file, compression='gzip', engine='pyarrow')\n",
    "\n",
    "    print(\"FINISHED PROCESSING DAILY DATA\")\n",
    "    # display(df_daily)\n",
    "    return df_daily\n",
    "\n",
    "def process_monthly_data(dataframe=None, directory=\"\", add_meta_data=False):\n",
    "\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        df = pd.read_parquet(directory)\n",
    "    else:\n",
    "        df = dataframe.copy()\n",
    "\n",
    "    df['month_year'] = df['Datetime'].dt.to_period('M')\n",
    "    # Define the date column that you want to group by (replace \"date_column\" with the name of your column)\n",
    "    min_values_per_month = 24\n",
    "\n",
    "    # Create a new column with the month and year of the date column\n",
    "\n",
    "    # Group the data by weather station and date\n",
    "    grouped = df.groupby(['stid','month_year'])\n",
    "\n",
    "    # Specify columns containing numerical values to be averaged\n",
    "    columns_to_average = (df\n",
    "                .select_dtypes(exclude=['object'])\n",
    "                .drop(columns=['Datetime', 'DayOfYear', 'DayOfCentury'])\n",
    "                .columns\n",
    "    )\n",
    "\n",
    "    # Calculate the number of non-NaN values for each variable within each group\n",
    "    valid_date_observations = grouped[columns_to_average].apply(lambda x: x.notna().sum() <= min_values_per_month)\n",
    "\n",
    "    # Calculate average per day per station\n",
    "    df_filtered = grouped[columns_to_average].mean()\n",
    "\n",
    "    #Remove means with less than 20 observations per day\n",
    "    df_masked = df_filtered.mask(valid_date_observations, np.nan)\n",
    "\n",
    "    df_monthly = df_masked.reset_index().copy()\n",
    "\n",
    "    df_monthly[\"Datetime\"] = pd.to_datetime(df_monthly['month_year'].astype(str) + '-01')\n",
    "\n",
    "    if add_meta_data==True:\n",
    "        df_monthly = add_nice_to_haves(df_monthly, 'monthly')\n",
    "\n",
    "    #display(df_monthly)\n",
    "\n",
    "    # Convert the DataFrame to a compressed Parquet file\n",
    "    output_file = \"..\\\\Data\\\\new_promice\\\\all_promice_data_monthly.parquet.gzip\"\n",
    "    df_monthly.to_parquet(output_file, compression='gzip', engine='pyarrow')\n",
    "\n",
    "    print('FINISHED PROCESSING MONTHLY DATA')\n",
    "    return df_monthly\n",
    "\n",
    "###########################################################################################\n",
    "### Helper functions\n",
    "\n",
    "def add_station_info(df):\n",
    "    station = pd.read_csv('../data/new_promice/AWS_station_locations.csv')\n",
    "    station.rename(columns={'timestamp':'station_location_timestamp'})\n",
    "    df.merge(station, how='left',on=['stid','stid'])\n",
    "    return df\n",
    "\n",
    "# helper functions for adding metadata like season, day, month, year, date, DayOfYear and DayOfCentury\n",
    "def add_nice_to_haves(df, period):\n",
    "    def add_season(df):\n",
    "        seasons = {\n",
    "            1: \"Winter\",\n",
    "            2: \"Winter\",\n",
    "            3: \"Spring\",\n",
    "            4: \"Spring\",\n",
    "            5: \"Spring\",\n",
    "            6: \"Summer\",\n",
    "            7: \"Summer\",\n",
    "            8: \"Summer\",\n",
    "            9: \"Autumn\",\n",
    "            10: \"Autumn\",\n",
    "            11: \"Autumn\",\n",
    "            12: \"Winter\",\n",
    "        }\n",
    "\n",
    "        # Extract the month from the index and use the dictionary to map it to the corresponding season\n",
    "        df[\"season\"] = df['Datetime'].dt.month.map(seasons)\n",
    "        return df\n",
    "\n",
    "    def add_common(df):\n",
    "        df[\"year\"] = df['Datetime'].dt.strftime(\"%Y\")\n",
    "        df[\"month\"] = df['Datetime'].dt.strftime(\"%B\")\n",
    "        df[\"date\"] = df['Datetime'].dt.date\n",
    "        df['DayOfYear'] = df['Datetime'].dt.dayofyear \n",
    "        df['DayOfCentury'] = df['Datetime'].dt.dayofyear+365*(df['Datetime'].dt.year-1)\n",
    "        df = add_season(df)\n",
    "        return df\n",
    "        \n",
    "    def add_day(df):\n",
    "        # Add day column to dataframe\n",
    "        df[\"day\"] = df['Datetime'].dt.strftime(\"%d\")\n",
    "        return df\n",
    "\n",
    "    def add_hour(df):\n",
    "        # Add hour column to dataframe\n",
    "        df[\"hour\"] = df['Datetime'].dt.strftime(\"%h\")\n",
    "        return df\n",
    "\n",
    "    if period == 'hourly':\n",
    "        df = add_hour(\n",
    "            add_day(\n",
    "            add_common(df)))\n",
    "\n",
    "    elif period == 'daily':\n",
    "        df = add_day(\n",
    "            add_common(df))\n",
    "    elif period == 'monthly':\n",
    "        df = add_common(df)\n",
    "    \n",
    "    return df \n",
    "\n",
    "#### Unused code\n",
    "    # Process data\n",
    "    # echo -ne 'Processing dairly data...\\r'\n",
    "    # python scripts/process_data_daily.py\n",
    "    # echo -ne 'Processing hourly data...\\r'\n",
    "    # python scripts/process_data_hourly.py\n",
    "\n",
    "    # Delete unprocessed data\n",
    "    # rm -r data_daily data_hourly\n",
    "\n",
    "    # %% process data hourly\n",
    "    # Reading station metadata\n",
    "\n",
    "    # Delete irrelevant columns from dataframe (i.e. null columns and flag columns)\n",
    "    # null_columns = df_hourly.columns[df_hourly.isnull().all()]\n",
    "    # flag_columns = df_hourly.filter(regex=\"flag$\").columns\n",
    "    # print(null_columns)\n",
    "    # print(flag_columns)\n",
    "\n",
    "    #df_hourly = df_hourly.drop(\n",
    "    #    columns=[\n",
    "    #           'gps_geounit', \n",
    "    #           'batt_v_ini', \n",
    "    #           'freq_vw',\n",
    "    #    ]\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv_files()\n",
    "\n",
    "header = pd.read_csv('metadata/promice_header.csv', sep = \";\")\n",
    "\n",
    "df_hourly = process_hourly_data(dataframe=df, add_metadata=True)\n",
    "df_hourly = df_hourly.rename(columns = header.set_index('standard_name')['long_name'])\n",
    "\n",
    "df_hourly = process_hourly_data(directory=\"../data/new_promice/all_promice_data.parquet.gzip\")\n",
    "############################################\n",
    "\n",
    "df_daily = process_daily_data(dataframe=df_hourly, add_meta_data=True)\n",
    "df_daily = df_daily.rename(columns = header.set_index('standard_name')['long_name'])\n",
    "\n",
    "df_daily = process_daily_data(directory=\"../data/new_promice/all_promice_data_hourly.parquet.gzip\", add_meta_data=True)\n",
    "\n",
    "############################################\n",
    "df_monthly = process_monthly_data(dataframe=df_daily, add_meta_data=True)\n",
    "df_monthly = df_monthly.rename(columns = header.set_index('standard_name')['long_name'])\n",
    "\n",
    "df_monthly = process_monthly_data(directory='..\\\\Data\\\\new_promice\\\\all_promice_data_daily.parquet.gzip', add_meta_data=True)\n",
    "\n",
    "### helper function to add station information such as # of booms, location and classification\n",
    "\n",
    "# df_hourly = add_station_info(df_hourly)\n",
    "# df_daily = add_station_info(df_daily)\n",
    "# df_monthly = add_station_info(df_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = df_hourly.columns[df_hourly.isnull().all()]\n",
    "flag_columns = df_hourly.filter(regex=\"flag$\").columns\n",
    "print(\"null columns:\\n\", null_columns)\n",
    "print(\"flag_columns:\\n\", flag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zyy-tj5MR42i"
   },
   "source": [
    "Promice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "BkQ-3yLP-37W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-16 12:34:59--  https://dataverse.geus.dk/api/datasets/:persistentId/dirindex?persistentId=doi:10.22008/FK2/8SS7EW\n",
      "Resolving dataverse.geus.dk (dataverse.geus.dk)... 194.182.159.137\n",
      "Connecting to dataverse.geus.dk (dataverse.geus.dk)|194.182.159.137|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15287 (15K) [text/html]\n",
      "Saving to: ‘.index.html’\n",
      "\n",
      ".index.html         100%[===================>]  14,93K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2023-02-16 12:34:59 (904 KB/s) - ‘.index.html’ saved [15287/15287]\n",
      "\n",
      "--2023-02-16 12:34:59--  https://dataverse.geus.dk/api/access/datafile/34687\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 545593 (533K) [text/plain]\n",
      "Saving to: ‘CEN_day_v03.txt’\n",
      "\n",
      "CEN_day_v03.txt     100%[===================>] 532,81K  --.-KB/s    in 0,07s   \n",
      "\n",
      "2023-02-16 12:35:00 (7,70 MB/s) - ‘CEN_day_v03.txt’ saved [545593/545593]\n",
      "\n",
      "--2023-02-16 12:35:00--  https://dataverse.geus.dk/api/access/datafile/34696\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13332409 (13M) [text/plain]\n",
      "Saving to: ‘CEN_hour_v03.txt’\n",
      "\n",
      "CEN_hour_v03.txt    100%[===================>]  12,71M  47,3MB/s    in 0,3s    \n",
      "\n",
      "2023-02-16 12:35:00 (47,3 MB/s) - ‘CEN_hour_v03.txt’ saved [13332409/13332409]\n",
      "\n",
      "--2023-02-16 12:35:00--  https://dataverse.geus.dk/api/access/datafile/34641\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10336 (10K) [text/plain]\n",
      "Saving to: ‘CEN_month_v03.txt’\n",
      "\n",
      "CEN_month_v03.txt   100%[===================>]  10,09K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:00 (52,2 MB/s) - ‘CEN_month_v03.txt’ saved [10336/10336]\n",
      "\n",
      "--2023-02-16 12:35:00--  https://dataverse.geus.dk/api/access/datafile/34671\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 736213 (719K) [text/plain]\n",
      "Saving to: ‘EGP_day_v03.txt’\n",
      "\n",
      "EGP_day_v03.txt     100%[===================>] 718,96K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2023-02-16 12:35:00 (55,2 MB/s) - ‘EGP_day_v03.txt’ saved [736213/736213]\n",
      "\n",
      "--2023-02-16 12:35:00--  https://dataverse.geus.dk/api/access/datafile/34720\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17998009 (17M) [text/plain]\n",
      "Saving to: ‘EGP_hour_v03.txt’\n",
      "\n",
      "EGP_hour_v03.txt    100%[===================>]  17,16M  25,2MB/s    in 0,7s    \n",
      "\n",
      "2023-02-16 12:35:01 (25,2 MB/s) - ‘EGP_hour_v03.txt’ saved [17998009/17998009]\n",
      "\n",
      "--2023-02-16 12:35:01--  https://dataverse.geus.dk/api/access/datafile/34643\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13549 (13K) [text/plain]\n",
      "Saving to: ‘EGP_month_v03.txt’\n",
      "\n",
      "EGP_month_v03.txt   100%[===================>]  13,23K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:01 (35,0 MB/s) - ‘EGP_month_v03.txt’ saved [13549/13549]\n",
      "\n",
      "--2023-02-16 12:35:01--  https://dataverse.geus.dk/api/access/datafile/34672\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1387498 (1,3M) [text/plain]\n",
      "Saving to: ‘KAN_B_day_v03.txt’\n",
      "\n",
      "KAN_B_day_v03.txt   100%[===================>]   1,32M  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-02-16 12:35:01 (24,0 MB/s) - ‘KAN_B_day_v03.txt’ saved [1387498/1387498]\n",
      "\n",
      "--2023-02-16 12:35:01--  https://dataverse.geus.dk/api/access/datafile/34718\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33938809 (32M) [text/plain]\n",
      "Saving to: ‘KAN_B_hour_v03.txt’\n",
      "\n",
      "KAN_B_hour_v03.txt  100%[===================>]  32,37M  27,3MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:02 (27,3 MB/s) - ‘KAN_B_hour_v03.txt’ saved [33938809/33938809]\n",
      "\n",
      "--2023-02-16 12:35:02--  https://dataverse.geus.dk/api/access/datafile/34657\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25078 (24K) [text/plain]\n",
      "Saving to: ‘KAN_B_month_v03.txt’\n",
      "\n",
      "KAN_B_month_v03.txt 100%[===================>]  24,49K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:02 (46,3 MB/s) - ‘KAN_B_month_v03.txt’ saved [25078/25078]\n",
      "\n",
      "--2023-02-16 12:35:02--  https://dataverse.geus.dk/api/access/datafile/34692\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1724260 (1,6M) [text/plain]\n",
      "Saving to: ‘KAN_L_day_v03.txt’\n",
      "\n",
      "KAN_L_day_v03.txt   100%[===================>]   1,64M  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-02-16 12:35:02 (26,1 MB/s) - ‘KAN_L_day_v03.txt’ saved [1724260/1724260]\n",
      "\n",
      "--2023-02-16 12:35:02--  https://dataverse.geus.dk/api/access/datafile/34722\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42181369 (40M) [text/plain]\n",
      "Saving to: ‘KAN_L_hour_v03.txt’\n",
      "\n",
      "KAN_L_hour_v03.txt  100%[===================>]  40,23M  30,3MB/s    in 1,3s    \n",
      "\n",
      "2023-02-16 12:35:04 (30,3 MB/s) - ‘KAN_L_hour_v03.txt’ saved [42181369/42181369]\n",
      "\n",
      "--2023-02-16 12:35:04--  https://dataverse.geus.dk/api/access/datafile/34664\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30937 (30K) [text/plain]\n",
      "Saving to: ‘KAN_L_month_v03.txt’\n",
      "\n",
      "KAN_L_month_v03.txt 100%[===================>]  30,21K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:04 (61,3 MB/s) - ‘KAN_L_month_v03.txt’ saved [30937/30937]\n",
      "\n",
      "--2023-02-16 12:35:04--  https://dataverse.geus.dk/api/access/datafile/34678\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1723907 (1,6M) [text/plain]\n",
      "Saving to: ‘KAN_M_day_v03.txt’\n",
      "\n",
      "KAN_M_day_v03.txt   100%[===================>]   1,64M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:04 (35,6 MB/s) - ‘KAN_M_day_v03.txt’ saved [1723907/1723907]\n",
      "\n",
      "--2023-02-16 12:35:04--  https://dataverse.geus.dk/api/access/datafile/34698\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42172729 (40M) [text/plain]\n",
      "Saving to: ‘KAN_M_hour_v03.txt’\n",
      "\n",
      "KAN_M_hour_v03.txt  100%[===================>]  40,22M  31,8MB/s    in 1,3s    \n",
      "\n",
      "2023-02-16 12:35:05 (31,8 MB/s) - ‘KAN_M_hour_v03.txt’ saved [42172729/42172729]\n",
      "\n",
      "--2023-02-16 12:35:05--  https://dataverse.geus.dk/api/access/datafile/34644\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30937 (30K) [text/plain]\n",
      "Saving to: ‘KAN_M_month_v03.txt’\n",
      "\n",
      "KAN_M_month_v03.txt 100%[===================>]  30,21K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:05 (58,9 MB/s) - ‘KAN_M_month_v03.txt’ saved [30937/30937]\n",
      "\n",
      "--2023-02-16 12:35:05--  https://dataverse.geus.dk/api/access/datafile/34676\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648365 (1,6M) [text/plain]\n",
      "Saving to: ‘KAN_U_day_v03.txt’\n",
      "\n",
      "KAN_U_day_v03.txt   100%[===================>]   1,57M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:06 (32,3 MB/s) - ‘KAN_U_day_v03.txt’ saved [1648365/1648365]\n",
      "\n",
      "--2023-02-16 12:35:06--  https://dataverse.geus.dk/api/access/datafile/34705\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 40323769 (38M) [text/plain]\n",
      "Saving to: ‘KAN_U_hour_v03.txt’\n",
      "\n",
      "KAN_U_hour_v03.txt  100%[===================>]  38,46M  31,3MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:07 (31,3 MB/s) - ‘KAN_U_hour_v03.txt’ saved [40323769/40323769]\n",
      "\n",
      "--2023-02-16 12:35:07--  https://dataverse.geus.dk/api/access/datafile/34666\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29614 (29K) [text/plain]\n",
      "Saving to: ‘KAN_U_month_v03.txt’\n",
      "\n",
      "KAN_U_month_v03.txt 100%[===================>]  28,92K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:07 (85,1 MB/s) - ‘KAN_U_month_v03.txt’ saved [29614/29614]\n",
      "\n",
      "--2023-02-16 12:35:07--  https://dataverse.geus.dk/api/access/datafile/34689\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1740498 (1,7M) [text/plain]\n",
      "Saving to: ‘KPC_L_day_v03.txt’\n",
      "\n",
      "KPC_L_day_v03.txt   100%[===================>]   1,66M  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-02-16 12:35:07 (26,0 MB/s) - ‘KPC_L_day_v03.txt’ saved [1740498/1740498]\n",
      "\n",
      "--2023-02-16 12:35:07--  https://dataverse.geus.dk/api/access/datafile/34715\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42578809 (41M) [text/plain]\n",
      "Saving to: ‘KPC_L_hour_v03.txt’\n",
      "\n",
      "KPC_L_hour_v03.txt  100%[===================>]  40,61M  18,0MB/s    in 2,3s    \n",
      "\n",
      "2023-02-16 12:35:09 (18,0 MB/s) - ‘KPC_L_hour_v03.txt’ saved [42578809/42578809]\n",
      "\n",
      "--2023-02-16 12:35:09--  https://dataverse.geus.dk/api/access/datafile/34658\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31315 (31K) [text/plain]\n",
      "Saving to: ‘KPC_L_month_v03.txt’\n",
      "\n",
      "KPC_L_month_v03.txt 100%[===================>]  30,58K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:09 (61,8 MB/s) - ‘KPC_L_month_v03.txt’ saved [31315/31315]\n",
      "\n",
      "--2023-02-16 12:35:09--  https://dataverse.geus.dk/api/access/datafile/34691\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1740498 (1,7M) [text/plain]\n",
      "Saving to: ‘KPC_U_day_v03.txt’\n",
      "\n",
      "KPC_U_day_v03.txt   100%[===================>]   1,66M  --.-KB/s    in 0,04s   \n",
      "\n",
      "2023-02-16 12:35:10 (37,1 MB/s) - ‘KPC_U_day_v03.txt’ saved [1740498/1740498]\n",
      "\n",
      "--2023-02-16 12:35:10--  https://dataverse.geus.dk/api/access/datafile/34721\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42578809 (41M) [text/plain]\n",
      "Saving to: ‘KPC_U_hour_v03.txt’\n",
      "\n",
      "KPC_U_hour_v03.txt  100%[===================>]  40,61M  34,3MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:11 (34,3 MB/s) - ‘KPC_U_hour_v03.txt’ saved [42578809/42578809]\n",
      "\n",
      "--2023-02-16 12:35:11--  https://dataverse.geus.dk/api/access/datafile/34651\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31315 (31K) [text/plain]\n",
      "Saving to: ‘KPC_U_month_v03.txt’\n",
      "\n",
      "KPC_U_month_v03.txt 100%[===================>]  30,58K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:11 (65,9 MB/s) - ‘KPC_U_month_v03.txt’ saved [31315/31315]\n",
      "\n",
      "--2023-02-16 12:35:11--  https://dataverse.geus.dk/api/access/datafile/34690\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1637775 (1,6M) [text/plain]\n",
      "Saving to: ‘MIT_day_v03.txt’\n",
      "\n",
      "MIT_day_v03.txt     100%[===================>]   1,56M  --.-KB/s    in 0,04s   \n",
      "\n",
      "2023-02-16 12:35:11 (35,1 MB/s) - ‘MIT_day_v03.txt’ saved [1637775/1637775]\n",
      "\n",
      "--2023-02-16 12:35:11--  https://dataverse.geus.dk/api/access/datafile/34701\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 40064569 (38M) [text/plain]\n",
      "Saving to: ‘MIT_hour_v03.txt’\n",
      "\n",
      "MIT_hour_v03.txt    100%[===================>]  38,21M  35,5MB/s    in 1,1s    \n",
      "\n",
      "2023-02-16 12:35:12 (35,5 MB/s) - ‘MIT_hour_v03.txt’ saved [40064569/40064569]\n",
      "\n",
      "--2023-02-16 12:35:12--  https://dataverse.geus.dk/api/access/datafile/34660\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29425 (29K) [text/plain]\n",
      "Saving to: ‘MIT_month_v03.txt’\n",
      "\n",
      "MIT_month_v03.txt   100%[===================>]  28,74K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:12 (72,9 MB/s) - ‘MIT_month_v03.txt’ saved [29425/29425]\n",
      "\n",
      "--2023-02-16 12:35:12--  https://dataverse.geus.dk/api/access/datafile/34679\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 963192 (941K) [text/plain]\n",
      "Saving to: ‘NUK_K_day_v03.txt’\n",
      "\n",
      "NUK_K_day_v03.txt   100%[===================>] 940,62K  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:12 (36,7 MB/s) - ‘NUK_K_day_v03.txt’ saved [963192/963192]\n",
      "\n",
      "--2023-02-16 12:35:12--  https://dataverse.geus.dk/api/access/datafile/34702\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23553529 (22M) [text/plain]\n",
      "Saving to: ‘NUK_K_hour_v03.txt’\n",
      "\n",
      "NUK_K_hour_v03.txt  100%[===================>]  22,46M  40,1MB/s    in 0,6s    \n",
      "\n",
      "2023-02-16 12:35:13 (40,1 MB/s) - ‘NUK_K_hour_v03.txt’ saved [23553529/23553529]\n",
      "\n",
      "--2023-02-16 12:35:13--  https://dataverse.geus.dk/api/access/datafile/34665\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17707 (17K) [text/plain]\n",
      "Saving to: ‘NUK_K_month_v03.txt’\n",
      "\n",
      "NUK_K_month_v03.txt 100%[===================>]  17,29K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:13 (68,9 MB/s) - ‘NUK_K_month_v03.txt’ saved [17707/17707]\n",
      "\n",
      "--2023-02-16 12:35:13--  https://dataverse.geus.dk/api/access/datafile/34684\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1857694 (1,8M) [text/plain]\n",
      "Saving to: ‘NUK_L_day_v03.txt’\n",
      "\n",
      "NUK_L_day_v03.txt   100%[===================>]   1,77M  --.-KB/s    in 0,04s   \n",
      "\n",
      "2023-02-16 12:35:13 (40,5 MB/s) - ‘NUK_L_day_v03.txt’ saved [1857694/1857694]\n",
      "\n",
      "--2023-02-16 12:35:13--  https://dataverse.geus.dk/api/access/datafile/34699\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45447289 (43M) [text/plain]\n",
      "Saving to: ‘NUK_L_hour_v03.txt’\n",
      "\n",
      "NUK_L_hour_v03.txt  100%[===================>]  43,34M  39,6MB/s    in 1,1s    \n",
      "\n",
      "2023-02-16 12:35:14 (39,6 MB/s) - ‘NUK_L_hour_v03.txt’ saved [45447289/45447289]\n",
      "\n",
      "--2023-02-16 12:35:14--  https://dataverse.geus.dk/api/access/datafile/34645\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33394 (33K) [text/plain]\n",
      "Saving to: ‘NUK_L_month_v03.txt’\n",
      "\n",
      "NUK_L_month_v03.txt 100%[===================>]  32,61K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:14 (53,6 MB/s) - ‘NUK_L_month_v03.txt’ saved [33394/33394]\n",
      "\n",
      "--2023-02-16 12:35:14--  https://dataverse.geus.dk/api/access/datafile/34694\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 508229 (496K) [text/plain]\n",
      "Saving to: ‘NUK_N_day_v03.txt’\n",
      "\n",
      "NUK_N_day_v03.txt   100%[===================>] 496,32K  --.-KB/s    in 0,009s  \n",
      "\n",
      "2023-02-16 12:35:14 (51,9 MB/s) - ‘NUK_N_day_v03.txt’ saved [508229/508229]\n",
      "\n",
      "--2023-02-16 12:35:14--  https://dataverse.geus.dk/api/access/datafile/34717\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12422042 (12M) [text/plain]\n",
      "Saving to: ‘NUK_N_hour_v03.txt’\n",
      "\n",
      "NUK_N_hour_v03.txt  100%[===================>]  11,85M  38,9MB/s    in 0,3s    \n",
      "\n",
      "2023-02-16 12:35:15 (38,9 MB/s) - ‘NUK_N_hour_v03.txt’ saved [12422042/12422042]\n",
      "\n",
      "--2023-02-16 12:35:15--  https://dataverse.geus.dk/api/access/datafile/34663\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9476 (9,3K) [text/plain]\n",
      "Saving to: ‘NUK_N_month_v03.txt’\n",
      "\n",
      "NUK_N_month_v03.txt 100%[===================>]   9,25K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:15 (42,2 MB/s) - ‘NUK_N_month_v03.txt’ saved [9476/9476]\n",
      "\n",
      "--2023-02-16 12:35:15--  https://dataverse.geus.dk/api/access/datafile/34693\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1857694 (1,8M) [text/plain]\n",
      "Saving to: ‘NUK_U_day_v03.txt’\n",
      "\n",
      "NUK_U_day_v03.txt   100%[===================>]   1,77M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:15 (32,4 MB/s) - ‘NUK_U_day_v03.txt’ saved [1857694/1857694]\n",
      "\n",
      "--2023-02-16 12:35:15--  https://dataverse.geus.dk/api/access/datafile/34714\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45447289 (43M) [text/plain]\n",
      "Saving to: ‘NUK_U_hour_v03.txt’\n",
      "\n",
      "NUK_U_hour_v03.txt  100%[===================>]  43,34M  40,7MB/s    in 1,1s    \n",
      "\n",
      "2023-02-16 12:35:16 (40,7 MB/s) - ‘NUK_U_hour_v03.txt’ saved [45447289/45447289]\n",
      "\n",
      "--2023-02-16 12:35:16--  https://dataverse.geus.dk/api/access/datafile/34653\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33394 (33K) [text/plain]\n",
      "Saving to: ‘NUK_U_month_v03.txt’\n",
      "\n",
      "NUK_U_month_v03.txt 100%[===================>]  32,61K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:16 (29,5 MB/s) - ‘NUK_U_month_v03.txt’ saved [33394/33394]\n",
      "\n",
      "--2023-02-16 12:35:16--  https://dataverse.geus.dk/api/access/datafile/34804\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 746194 (729K) [image/png]\n",
      "Saving to: ‘PROMICE AWS map and annotated photo.png’\n",
      "\n",
      "PROMICE AWS map and 100%[===================>] 728,71K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2023-02-16 12:35:16 (51,7 MB/s) - ‘PROMICE AWS map and annotated photo.png’ saved [746194/746194]\n",
      "\n",
      "--2023-02-16 12:35:16--  https://dataverse.geus.dk/api/access/datafile/34805\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102563 (100K) [application/pdf]\n",
      "Saving to: ‘PROMICE_coordinates.pdf’\n",
      "\n",
      "PROMICE_coordinates 100%[===================>] 100,16K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2023-02-16 12:35:16 (5,35 MB/s) - ‘PROMICE_coordinates.pdf’ saved [102563/102563]\n",
      "\n",
      "--2023-02-16 12:35:16--  https://dataverse.geus.dk/api/access/datafile/34683\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 382615 (374K) [text/plain]\n",
      "Saving to: ‘QAS_A_day_v03.txt’\n",
      "\n",
      "QAS_A_day_v03.txt   100%[===================>] 373,65K  --.-KB/s    in 0,007s  \n",
      "\n",
      "2023-02-16 12:35:16 (53,7 MB/s) - ‘QAS_A_day_v03.txt’ saved [382615/382615]\n",
      "\n",
      "--2023-02-16 12:35:16--  https://dataverse.geus.dk/api/access/datafile/34719\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9346490 (8,9M) [text/plain]\n",
      "Saving to: ‘QAS_A_hour_v03.txt’\n",
      "\n",
      "QAS_A_hour_v03.txt  100%[===================>]   8,91M  40,0MB/s    in 0,2s    \n",
      "\n",
      "2023-02-16 12:35:17 (40,0 MB/s) - ‘QAS_A_hour_v03.txt’ saved [9346490/9346490]\n",
      "\n",
      "--2023-02-16 12:35:17--  https://dataverse.geus.dk/api/access/datafile/34655\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7280 (7,1K) [text/plain]\n",
      "Saving to: ‘QAS_A_month_v03.txt’\n",
      "\n",
      "QAS_A_month_v03.txt 100%[===================>]   7,11K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:17 (63,1 MB/s) - ‘QAS_A_month_v03.txt’ saved [7280/7280]\n",
      "\n",
      "--2023-02-16 12:35:17--  https://dataverse.geus.dk/api/access/datafile/34675\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1855929 (1,8M) [text/plain]\n",
      "Saving to: ‘QAS_L_day_v03.txt’\n",
      "\n",
      "QAS_L_day_v03.txt   100%[===================>]   1,77M  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-02-16 12:35:17 (30,6 MB/s) - ‘QAS_L_day_v03.txt’ saved [1855929/1855929]\n",
      "\n",
      "--2023-02-16 12:35:17--  https://dataverse.geus.dk/api/access/datafile/34713\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45404089 (43M) [text/plain]\n",
      "Saving to: ‘QAS_L_hour_v03.txt’\n",
      "\n",
      "QAS_L_hour_v03.txt  100%[===================>]  43,30M  35,9MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:18 (35,9 MB/s) - ‘QAS_L_hour_v03.txt’ saved [45404089/45404089]\n",
      "\n",
      "--2023-02-16 12:35:18--  https://dataverse.geus.dk/api/access/datafile/34647\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33394 (33K) [text/plain]\n",
      "Saving to: ‘QAS_L_month_v03.txt’\n",
      "\n",
      "QAS_L_month_v03.txt 100%[===================>]  32,61K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:18 (47,8 MB/s) - ‘QAS_L_month_v03.txt’ saved [33394/33394]\n",
      "\n",
      "--2023-02-16 12:35:18--  https://dataverse.geus.dk/api/access/datafile/34669\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 700207 (684K) [text/plain]\n",
      "Saving to: ‘QAS_M_day_v03.txt’\n",
      "\n",
      "QAS_M_day_v03.txt   100%[===================>] 683,80K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2023-02-16 12:35:18 (58,6 MB/s) - ‘QAS_M_day_v03.txt’ saved [700207/700207]\n",
      "\n",
      "--2023-02-16 12:35:18--  https://dataverse.geus.dk/api/access/datafile/34716\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17116729 (16M) [text/plain]\n",
      "Saving to: ‘QAS_M_hour_v03.txt’\n",
      "\n",
      "QAS_M_hour_v03.txt  100%[===================>]  16,32M  41,5MB/s    in 0,4s    \n",
      "\n",
      "2023-02-16 12:35:19 (41,5 MB/s) - ‘QAS_M_hour_v03.txt’ saved [17116729/17116729]\n",
      "\n",
      "--2023-02-16 12:35:19--  https://dataverse.geus.dk/api/access/datafile/34661\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12982 (13K) [text/plain]\n",
      "Saving to: ‘QAS_M_month_v03.txt’\n",
      "\n",
      "QAS_M_month_v03.txt 100%[===================>]  12,68K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:19 (39,7 MB/s) - ‘QAS_M_month_v03.txt’ saved [12982/12982]\n",
      "\n",
      "--2023-02-16 12:35:19--  https://dataverse.geus.dk/api/access/datafile/34686\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1733085 (1,7M) [text/plain]\n",
      "Saving to: ‘QAS_U_day_v03.txt’\n",
      "\n",
      "QAS_U_day_v03.txt   100%[===================>]   1,65M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:19 (31,4 MB/s) - ‘QAS_U_day_v03.txt’ saved [1733085/1733085]\n",
      "\n",
      "--2023-02-16 12:35:19--  https://dataverse.geus.dk/api/access/datafile/34709\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42397369 (40M) [text/plain]\n",
      "Saving to: ‘QAS_U_hour_v03.txt’\n",
      "\n",
      "QAS_U_hour_v03.txt  100%[===================>]  40,43M  32,3MB/s    in 1,3s    \n",
      "\n",
      "2023-02-16 12:35:20 (32,3 MB/s) - ‘QAS_U_hour_v03.txt’ saved [42397369/42397369]\n",
      "\n",
      "--2023-02-16 12:35:20--  https://dataverse.geus.dk/api/access/datafile/34652\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31126 (30K) [text/plain]\n",
      "Saving to: ‘QAS_U_month_v03.txt’\n",
      "\n",
      "QAS_U_month_v03.txt 100%[===================>]  30,40K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:20 (39,6 MB/s) - ‘QAS_U_month_v03.txt’ saved [31126/31126]\n",
      "\n",
      "--2023-02-16 12:35:20--  https://dataverse.geus.dk/api/access/datafile/34667\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 157047 (153K) [application/pdf]\n",
      "Saving to: ‘readme PROMICE AWS data.pdf’\n",
      "\n",
      "readme PROMICE AWS  100%[===================>] 153,37K  --.-KB/s    in 0,007s  \n",
      "\n",
      "2023-02-16 12:35:20 (22,1 MB/s) - ‘readme PROMICE AWS data.pdf’ saved [157047/157047]\n",
      "\n",
      "--2023-02-16 12:35:20--  https://dataverse.geus.dk/api/access/datafile/34695\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1738733 (1,7M) [text/plain]\n",
      "Saving to: ‘SCO_L_day_v03.txt’\n",
      "\n",
      "SCO_L_day_v03.txt   100%[===================>]   1,66M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:21 (35,1 MB/s) - ‘SCO_L_day_v03.txt’ saved [1738733/1738733]\n",
      "\n",
      "--2023-02-16 12:35:21--  https://dataverse.geus.dk/api/access/datafile/34706\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42535609 (41M) [text/plain]\n",
      "Saving to: ‘SCO_L_hour_v03.txt’\n",
      "\n",
      "SCO_L_hour_v03.txt  100%[===================>]  40,56M  35,0MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:22 (35,0 MB/s) - ‘SCO_L_hour_v03.txt’ saved [42535609/42535609]\n",
      "\n",
      "--2023-02-16 12:35:22--  https://dataverse.geus.dk/api/access/datafile/34654\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31315 (31K) [text/plain]\n",
      "Saving to: ‘SCO_L_month_v03.txt’\n",
      "\n",
      "SCO_L_month_v03.txt 100%[===================>]  30,58K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:22 (83,2 MB/s) - ‘SCO_L_month_v03.txt’ saved [31315/31315]\n",
      "\n",
      "--2023-02-16 12:35:22--  https://dataverse.geus.dk/api/access/datafile/34688\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1739086 (1,7M) [text/plain]\n",
      "Saving to: ‘SCO_U_day_v03.txt’\n",
      "\n",
      "SCO_U_day_v03.txt   100%[===================>]   1,66M  --.-KB/s    in 0,05s   \n",
      "\n",
      "2023-02-16 12:35:22 (35,9 MB/s) - ‘SCO_U_day_v03.txt’ saved [1739086/1739086]\n",
      "\n",
      "--2023-02-16 12:35:22--  https://dataverse.geus.dk/api/access/datafile/34703\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42544249 (41M) [text/plain]\n",
      "Saving to: ‘SCO_U_hour_v03.txt’\n",
      "\n",
      "SCO_U_hour_v03.txt  100%[===================>]  40,57M  33,1MB/s    in 1,2s    \n",
      "\n",
      "2023-02-16 12:35:23 (33,1 MB/s) - ‘SCO_U_hour_v03.txt’ saved [42544249/42544249]\n",
      "\n",
      "--2023-02-16 12:35:23--  https://dataverse.geus.dk/api/access/datafile/34659\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31315 (31K) [text/plain]\n",
      "Saving to: ‘SCO_U_month_v03.txt’\n",
      "\n",
      "SCO_U_month_v03.txt 100%[===================>]  30,58K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:23 (83,9 MB/s) - ‘SCO_U_month_v03.txt’ saved [31315/31315]\n",
      "\n",
      "--2023-02-16 12:35:23--  https://dataverse.geus.dk/api/access/datafile/34682\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1081094 (1,0M) [text/plain]\n",
      "Saving to: ‘TAS_A_day_v03.txt’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAS_A_day_v03.txt   100%[===================>]   1,03M  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:23 (35,9 MB/s) - ‘TAS_A_day_v03.txt’ saved [1081094/1081094]\n",
      "\n",
      "--2023-02-16 12:35:23--  https://dataverse.geus.dk/api/access/datafile/34700\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26439289 (25M) [text/plain]\n",
      "Saving to: ‘TAS_A_hour_v03.txt’\n",
      "\n",
      "TAS_A_hour_v03.txt  100%[===================>]  25,21M  35,8MB/s    in 0,7s    \n",
      "\n",
      "2023-02-16 12:35:24 (35,8 MB/s) - ‘TAS_A_hour_v03.txt’ saved [26439289/26439289]\n",
      "\n",
      "--2023-02-16 12:35:24--  https://dataverse.geus.dk/api/access/datafile/34656\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19786 (19K) [text/plain]\n",
      "Saving to: ‘TAS_A_month_v03.txt’\n",
      "\n",
      "TAS_A_month_v03.txt 100%[===================>]  19,32K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:24 (23,6 MB/s) - ‘TAS_A_month_v03.txt’ saved [19786/19786]\n",
      "\n",
      "--2023-02-16 12:35:24--  https://dataverse.geus.dk/api/access/datafile/34681\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1856635 (1,8M) [text/plain]\n",
      "Saving to: ‘TAS_L_day_v03.txt’\n",
      "\n",
      "TAS_L_day_v03.txt   100%[===================>]   1,77M  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-02-16 12:35:24 (32,0 MB/s) - ‘TAS_L_day_v03.txt’ saved [1856635/1856635]\n",
      "\n",
      "--2023-02-16 12:35:24--  https://dataverse.geus.dk/api/access/datafile/34711\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45421369 (43M) [text/plain]\n",
      "Saving to: ‘TAS_L_hour_v03.txt’\n",
      "\n",
      "TAS_L_hour_v03.txt  100%[===================>]  43,32M  38,3MB/s    in 1,1s    \n",
      "\n",
      "2023-02-16 12:35:25 (38,3 MB/s) - ‘TAS_L_hour_v03.txt’ saved [45421369/45421369]\n",
      "\n",
      "--2023-02-16 12:35:25--  https://dataverse.geus.dk/api/access/datafile/34662\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33394 (33K) [text/plain]\n",
      "Saving to: ‘TAS_L_month_v03.txt’\n",
      "\n",
      "TAS_L_month_v03.txt 100%[===================>]  32,61K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-02-16 12:35:26 (53,6 MB/s) - ‘TAS_L_month_v03.txt’ saved [33394/33394]\n",
      "\n",
      "--2023-02-16 12:35:26--  https://dataverse.geus.dk/api/access/datafile/34674\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 941979 (920K) [text/plain]\n",
      "Saving to: ‘TAS_U_day_v03.txt’\n",
      "\n",
      "TAS_U_day_v03.txt   100%[===================>] 919,90K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2023-02-16 12:35:26 (40,7 MB/s) - ‘TAS_U_day_v03.txt’ saved [941979/941979]\n",
      "\n",
      "--2023-02-16 12:35:26--  https://dataverse.geus.dk/api/access/datafile/34710\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23042042 (22M) [text/plain]\n",
      "Saving to: ‘TAS_U_hour_v03.txt’\n",
      "\n",
      "TAS_U_hour_v03.txt  100%[===================>]  21,97M  39,8MB/s    in 0,6s    \n",
      "\n",
      "2023-02-16 12:35:26 (39,8 MB/s) - ‘TAS_U_hour_v03.txt’ saved [23042042/23042042]\n",
      "\n",
      "--2023-02-16 12:35:26--  https://dataverse.geus.dk/api/access/datafile/34649\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16979 (17K) [text/plain]\n",
      "Saving to: ‘TAS_U_month_v03.txt’\n",
      "\n",
      "TAS_U_month_v03.txt 100%[===================>]  16,58K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:26 (64,8 MB/s) - ‘TAS_U_month_v03.txt’ saved [16979/16979]\n",
      "\n",
      "--2023-02-16 12:35:26--  https://dataverse.geus.dk/api/access/datafile/34673\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1474689 (1,4M) [text/plain]\n",
      "Saving to: ‘THU_L_day_v03.txt’\n",
      "\n",
      "THU_L_day_v03.txt   100%[===================>]   1,41M  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:26 (46,0 MB/s) - ‘THU_L_day_v03.txt’ saved [1474689/1474689]\n",
      "\n",
      "--2023-02-16 12:35:26--  https://dataverse.geus.dk/api/access/datafile/34697\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36072889 (34M) [text/plain]\n",
      "Saving to: ‘THU_L_hour_v03.txt’\n",
      "\n",
      "THU_L_hour_v03.txt  100%[===================>]  34,40M  35,2MB/s    in 1,0s    \n",
      "\n",
      "2023-02-16 12:35:27 (35,2 MB/s) - ‘THU_L_hour_v03.txt’ saved [36072889/36072889]\n",
      "\n",
      "--2023-02-16 12:35:27--  https://dataverse.geus.dk/api/access/datafile/34642\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26590 (26K) [text/plain]\n",
      "Saving to: ‘THU_L_month_v03.txt’\n",
      "\n",
      "THU_L_month_v03.txt 100%[===================>]  25,97K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:28 (73,1 MB/s) - ‘THU_L_month_v03.txt’ saved [26590/26590]\n",
      "\n",
      "--2023-02-16 12:35:28--  https://dataverse.geus.dk/api/access/datafile/34677\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 471110 (460K) [text/plain]\n",
      "Saving to: ‘THU_U2_day_v03.txt’\n",
      "\n",
      "THU_U2_day_v03.txt  100%[===================>] 460,07K  --.-KB/s    in 0,006s  \n",
      "\n",
      "2023-02-16 12:35:28 (74,5 MB/s) - ‘THU_U2_day_v03.txt’ saved [471110/471110]\n",
      "\n",
      "--2023-02-16 12:35:28--  https://dataverse.geus.dk/api/access/datafile/34707\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11509369 (11M) [text/plain]\n",
      "Saving to: ‘THU_U2_hour_v03.txt’\n",
      "\n",
      "THU_U2_hour_v03.txt 100%[===================>]  10,98M  33,2MB/s    in 0,3s    \n",
      "\n",
      "2023-02-16 12:35:28 (33,2 MB/s) - ‘THU_U2_hour_v03.txt’ saved [11509369/11509369]\n",
      "\n",
      "--2023-02-16 12:35:28--  https://dataverse.geus.dk/api/access/datafile/34650\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9013 (8,8K) [text/plain]\n",
      "Saving to: ‘THU_U2_month_v03.txt’\n",
      "\n",
      "THU_U2_month_v03.tx 100%[===================>]   8,80K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:28 (46,5 MB/s) - ‘THU_U2_month_v03.txt’ saved [9013/9013]\n",
      "\n",
      "--2023-02-16 12:35:28--  https://dataverse.geus.dk/api/access/datafile/34685\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1354669 (1,3M) [text/plain]\n",
      "Saving to: ‘THU_U_day_v03.txt’\n",
      "\n",
      "THU_U_day_v03.txt   100%[===================>]   1,29M  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:28 (38,1 MB/s) - ‘THU_U_day_v03.txt’ saved [1354669/1354669]\n",
      "\n",
      "--2023-02-16 12:35:28--  https://dataverse.geus.dk/api/access/datafile/34712\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33135289 (32M) [text/plain]\n",
      "Saving to: ‘THU_U_hour_v03.txt’\n",
      "\n",
      "THU_U_hour_v03.txt  100%[===================>]  31,60M  37,5MB/s    in 0,8s    \n",
      "\n",
      "2023-02-16 12:35:29 (37,5 MB/s) - ‘THU_U_hour_v03.txt’ saved [33135289/33135289]\n",
      "\n",
      "--2023-02-16 12:35:29--  https://dataverse.geus.dk/api/access/datafile/34668\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24511 (24K) [text/plain]\n",
      "Saving to: ‘THU_U_month_v03.txt’\n",
      "\n",
      "THU_U_month_v03.txt 100%[===================>]  23,94K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:29 (54,9 MB/s) - ‘THU_U_month_v03.txt’ saved [24511/24511]\n",
      "\n",
      "--2023-02-16 12:35:29--  https://dataverse.geus.dk/api/access/datafile/34680\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1600710 (1,5M) [text/plain]\n",
      "Saving to: ‘UPE_L_day_v03.txt’\n",
      "\n",
      "UPE_L_day_v03.txt   100%[===================>]   1,53M  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:29 (44,0 MB/s) - ‘UPE_L_day_v03.txt’ saved [1600710/1600710]\n",
      "\n",
      "--2023-02-16 12:35:29--  https://dataverse.geus.dk/api/access/datafile/34704\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39157369 (37M) [text/plain]\n",
      "Saving to: ‘UPE_L_hour_v03.txt’\n",
      "\n",
      "UPE_L_hour_v03.txt  100%[===================>]  37,34M  37,7MB/s    in 1,0s    \n",
      "\n",
      "2023-02-16 12:35:30 (37,7 MB/s) - ‘UPE_L_hour_v03.txt’ saved [39157369/39157369]\n",
      "\n",
      "--2023-02-16 12:35:30--  https://dataverse.geus.dk/api/access/datafile/34646\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28858 (28K) [text/plain]\n",
      "Saving to: ‘UPE_L_month_v03.txt’\n",
      "\n",
      "UPE_L_month_v03.txt 100%[===================>]  28,18K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:30 (86,0 MB/s) - ‘UPE_L_month_v03.txt’ saved [28858/28858]\n",
      "\n",
      "--2023-02-16 12:35:30--  https://dataverse.geus.dk/api/access/datafile/34670\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1600357 (1,5M) [text/plain]\n",
      "Saving to: ‘UPE_U_day_v03.txt’\n",
      "\n",
      "UPE_U_day_v03.txt   100%[===================>]   1,53M  --.-KB/s    in 0,03s   \n",
      "\n",
      "2023-02-16 12:35:30 (44,9 MB/s) - ‘UPE_U_day_v03.txt’ saved [1600357/1600357]\n",
      "\n",
      "--2023-02-16 12:35:30--  https://dataverse.geus.dk/api/access/datafile/34708\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39148729 (37M) [text/plain]\n",
      "Saving to: ‘UPE_U_hour_v03.txt’\n",
      "\n",
      "UPE_U_hour_v03.txt  100%[===================>]  37,33M  41,3MB/s    in 0,9s    \n",
      "\n",
      "2023-02-16 12:35:31 (41,3 MB/s) - ‘UPE_U_hour_v03.txt’ saved [39148729/39148729]\n",
      "\n",
      "--2023-02-16 12:35:31--  https://dataverse.geus.dk/api/access/datafile/34648\n",
      "Reusing existing connection to dataverse.geus.dk:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28858 (28K) [text/plain]\n",
      "Saving to: ‘UPE_U_month_v03.txt’\n",
      "\n",
      "UPE_U_month_v03.txt 100%[===================>]  28,18K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-16 12:35:31 (84,4 MB/s) - ‘UPE_U_month_v03.txt’ saved [28858/28858]\n",
      "\n",
      "FINISHED --2023-02-16 12:35:31--\n",
      "Total wall clock time: 32s\n",
      "Downloaded: 85 files, 890M in 27s (33,6 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget -r -e robots=off -nH --cut-dirs=3 --content-disposition \"https://dataverse.geus.dk/api/datasets/:persistentId/dirindex?persistentId=doi:10.22008/FK2/8SS7EW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CWscWKUJxkCA"
   },
   "outputs": [],
   "source": [
    "# save hourly data\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#path = r'/content'  # or unix / linux / mac path\n",
    "path = r'data/promice_data'\n",
    "\n",
    "# Get the files from the path provided in the OP\n",
    "files = Path(path).glob('*_hour_v03.txt')  # .rglob to get subdirectories\n",
    "\n",
    "dfs = list()\n",
    "for f in files:\n",
    "    data = pd.read_csv(f, delimiter=r\"\\s+\", engine='python')\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file'] = f.stem\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df = df.replace(-999, np.nan)\n",
    "\n",
    "df[\"Month\"] = df[\"MonthOfYear\"]\n",
    "df[\"Day\"] = df[\"DayOfMonth\"]\n",
    "df[\"Hour\"] = df[\"HourOfDay(UTC)\"]\n",
    "\n",
    "df[\"Datetime\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\", \"Hour\"]], format='%Y%m%d%h')\n",
    "\n",
    "# Save dataframe as parquet file\n",
    "df.to_parquet(\"data/promice_hourly.gzip\", compression=\"gzip\", engine='pyarrow')\n",
    "#df.to_parquet(\"/content/drive/MyDrive/Master_Thesis/data/promice_hourly.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vwZWPw1I_YPn"
   },
   "outputs": [],
   "source": [
    "# save daily data \n",
    "# Get the files from the path provided in the OP\n",
    "files = Path(path).glob('*_day_v03.txt')  # .rglob to get subdirectories\n",
    "\n",
    "dfs = list()\n",
    "for f in files:\n",
    "    data = pd.read_csv(f, delimiter=r\"\\s+\", engine='python')\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file'] = f.stem\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df = df.replace(-999, np.nan)\n",
    "\n",
    "df[\"Month\"] = df[\"MonthOfYear\"]\n",
    "df[\"Day\"] = df[\"DayOfMonth\"]\n",
    "\n",
    "df[\"Datetime\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]], format='%Y%m%d')\n",
    "\n",
    "# Save dataframe as parquet file\n",
    "df.to_parquet(\"data/promice_daily.gzip\", compression=\"gzip\", engine='pyarrow')\n",
    "#df.to_parquet(\"/content/drive/MyDrive/Master_Thesis/data/promice_daily.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bDnLS8bd_a3y"
   },
   "outputs": [],
   "source": [
    "# save monthly data \n",
    "# Get the files from the path provided in the OP\n",
    "files = Path(path).glob('*_month_v03.txt')  # .rglob to get subdirectories\n",
    "\n",
    "dfs = list()\n",
    "for f in files:\n",
    "    data = pd.read_csv(f, delimiter=r\"\\s+\", engine='python')\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file'] = f.stem\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df = df.replace(-999, np.nan)\n",
    "\n",
    "df[\"Month\"] = df[\"MonthOfYear\"]\n",
    "\n",
    "df[\"Datetime\"] = pd.to_datetime(['{}-{}-01'.format(y, m) for y, m in zip(df.Year, df.Month)])\n",
    "\n",
    "# Save dataframe as parquet file\n",
    "df.to_parquet(\"data/promice_monthly.gzip\", compression=\"gzip\", engine='pyarrow')\n",
    "#df.to_parquet(\"/content/drive/MyDrive/Master_Thesis/data/promice_monthly.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
