{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Mass Balance  - Ablation Period Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTbsuMgO3ery"
   },
   "source": [
    "Import relevant Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "yJLqdDNx3j-Y"
   },
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math as math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ODOhsaMP7u_"
   },
   "source": [
    "Set WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyrsistent import v\n",
    "os.getcwd()\n",
    "#os.chdir('/Users/asgerlyngeholst-hansen/Desktop/GEUS-Master-Thesis/')\n",
    "#os.chdir('C:\\\\Users\\\\nifu18ab\\\\Desktop\\\\GEUS-Master-Thesis')\n",
    "#os.chdir('/Users/nilsfulde/Desktop/GEUS-Master-Thesis')\n",
    "os.chdir('/Users/nilsfulde/Desktop/Master_Thesis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load New Promice Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading data and converting to datetime \n",
    "def load_hourly(path_to_file):\n",
    "    '''\n",
    "    Loading PROMICE data for a given path into a DataFrame.\n",
    "    + adding time index\n",
    "    \n",
    "    INTPUTS:\n",
    "        path_to_file: Path to the desired file containing PROMICE data [string]\n",
    "    \n",
    "    OUTPUTS:\n",
    "        df: Dataframe containing PROMICE data for the desired settings [DataFrame]\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    df['time'] = pd.to_datetime(df.time, utc=True)\n",
    "    df = df.set_index('time')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading data and converting to datetime \n",
    "def load_daily(path_to_file):\n",
    "    '''\n",
    "    Loading PROMICE data for a given path into a DataFrame.\n",
    "    + adding time index\n",
    "    \n",
    "    INTPUTS:\n",
    "        path_to_file: Path to the desired file containing PROMICE data [string]\n",
    "    \n",
    "    OUTPUTS:\n",
    "        df: Dataframe containing PROMICE data for the desired settings [DataFrame]\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    df['date'] = pd.to_datetime(df.date, utc=True)\n",
    "    df = df.set_index('date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Unique Stations\n",
    "station_list = pd.read_csv('data/promice/stations.csv')\n",
    "\n",
    "# Load Header\n",
    "header = pd.read_csv('metadata/promice_header.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to include only relevant features\n",
    "exclude_list = [                                                    'index', # excluded because of unimportant information\n",
    "                                                                     'stid', # excluded because of unimportant information\n",
    "#                                                'Air pressure (upper boom)',\n",
    "#                                             'Air temperature (upper boom)',\n",
    "                                            'Relative humidity (upper boom)', # excluded because of corrected feature\n",
    "#                               'Relative humidity (upper boom) - corrected',\n",
    "#                                           'Specific humidity (upper boom)',\n",
    "#                                                  'Wind speed (upper boom)',\n",
    "#                                         'Wind from direction (upper boom)',\n",
    "                                          'Downwelling shortwave radiation', # excluded because of corrected feature\n",
    "#                              'Downwelling shortwave radiation - corrected',\n",
    "                                            'Upwelling shortwave radiation', # excluded because of corrected feature\n",
    "#                                'Upwelling shortwave radiation - corrected',\n",
    "#                                                                   'Albedo', \n",
    "#                                           'Downwelling longwave radiation',\n",
    "#                                             'Upwelling longwave radiation',\n",
    "#                                                              'Cloud cover',\n",
    "#                                                      'Surface temperature',\n",
    "#                                            'Latent heat flux (upper boom)', \n",
    "#                                          'Sensible heat flux (upper boom)', \n",
    "                                                        'Upper boom height', # excluded because of unimportant information\n",
    "                                                             'Stake height', # excluded due to missing values\n",
    "                                      'Depth of pressure transducer in ice', # excluded due to derived correlation with y\n",
    "                          'Depth of pressure transducer in ice - corrected', # excluded due to derived correlation with y\n",
    "                   'Precipitation (upper boom) (cumulative solid & liquid)', # excluded because of corrected feature\n",
    "#       'Precipitation (upper boom) (cumulative solid & liquid) – corrected',\n",
    "                                              'Ice temperature at sensor 1', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 2', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 3', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 4', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 5', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 6', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 7', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 8', # excluded due to missing values\n",
    "                                                             'Tilt to east', # excluded because of unimportant information \n",
    "                                                            'Tilt to north', # excluded because of unimportant information\n",
    "                                         'Station rotation from true North', # excluded because of unimportant information\n",
    "                                                                 'Latitude', # excluded because of unimportant information\n",
    "                                                                'Longitude', # excluded because of unimportant information\n",
    "                                                                 'Altitude', # excluded because of unimportant information\n",
    "                                                                 'GPS time', # excluded because of unimportant information \n",
    "                               'Height of EGM96 geoid over WGS84 ellipsoid', # excluded because of unimportant information\n",
    "                                                                  'GeoUnit', # excluded because of unimportant information\n",
    "                             'GPS horizontal dillution of precision (HDOP)', # excluded because of unimportant information\n",
    "                                                 'GPS number of satellites', # excluded because of unimportant information\n",
    "                                                                  'Quality', # excluded because of unimportant information\n",
    "                                                          'Battery voltage', # excluded because of unimportant information\n",
    "                                                                    #    nan,\n",
    "                                           'Battery voltage (sample start)', # excluded because of unimportant information\n",
    "                                                 'Fan current (upper boom)', # excluded because of unimportant information\n",
    "                       'Frequency of vibrating wire in precipitation gauge', # excluded because of unimportant information\n",
    "                                                       'Logger temperature', # excluded because of unimportant information\n",
    "                                             'Radiation sensor temperature', # excluded because of unimportant information\n",
    "                                         'latitude from modem (email text)', # excluded because of unimportant information\n",
    "                                        'longitude from modem (email text)', # excluded because of unimportant information\n",
    "                                                         'Surface height 1', # excluded due to derived correlation with y\n",
    "                                                         'Surface height 1', # excluded due to derived correlation with y\n",
    "                                                        'z_surf_1_adj_flag', # excluded due to derived correlation with y\n",
    "                                                        'z_surf_2_adj_flag', # excluded due to derived correlation with y\n",
    "#                                'Surface height from combined measurements', \n",
    "                                   'Depth of ice temperature measurement 1', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 2', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 3', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 4', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 5', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 6', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 7', # excluded because of unimportant information\n",
    "                                   'Depth of ice temperature measurement 8', # excluded because of unimportant information\n",
    "                               'Ice temperature interpolated at 10 m depth', # excluded due to missing values\n",
    "                                                'Air pressure (lower boom)', # excluded due to missing values\n",
    "                                             'Air temperature (lower boom)', # excluded due to missing values\n",
    "                                           'Relative humidity (lower boom)', # excluded due to missing values\n",
    "                               'Relative humidity (lower boom) - corrected', # excluded due to missing values\n",
    "                                           'Specific humidity (lower boom)', # excluded due to missing values\n",
    "                                                  'Wind speed (lower boom)', # excluded due to missing values\n",
    "                                         'Wind from direction (lower boom)', # excluded due to missing values\n",
    "                                            'Latent heat flux (lower boom)', # excluded due to missing values\n",
    "                                          'Sensible heat flux (lower boom)', # excluded due to missing values\n",
    "                                                        'Lower boom height', # excluded due to missing values\n",
    "                   'Precipitation (lower boom) (cumulative solid & liquid)', # excluded due to missing values\n",
    "       'Precipitation (lower boom) (cumulative solid & liquid) – corrected', # excluded due to missing values\n",
    "                                              'Ice temperature at sensor 9', # excluded due to missing values\n",
    "                                             'Ice temperature at sensor 10', # excluded due to missing values\n",
    "                                             'Ice temperature at sensor 11', # excluded due to missing values\n",
    "                                                 'Fan current (lower boom)', # excluded due to missing values\n",
    "                                   'Depth of ice temperature measurement 9', # excluded due to missing values\n",
    "                                  'Depth of ice temperature measurement 10', # excluded due to missing values\n",
    "                                  'Depth of ice temperature measurement 11', # excluded due to missing values\n",
    "                                                        'z_pt_cor_adj_flag', # excluded due to derived correlation with y\n",
    "                              'Ice surface height adjusted for maintenance', # excluded due to derived correlation with y\n",
    "                                'Surface height adjusted for maintenance 1', # excluded due to derived correlation with y\n",
    "                                  'Surface height adjusted for maintenance', # excluded due to derived correlation with y\n",
    "#                                                                 'Datetime',\n",
    "#                                                                 'Ablation',  \n",
    "#                          'Surface height from combined measurements DELTA'  \n",
    "                                                       \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For All Stations - Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to define the data that is to be loaded\n",
    "\n",
    "import glob\n",
    "\n",
    "# Define the directory path where the CSV files are located\n",
    "input_path = 'data/promice/new_promice/daily_data'\n",
    "\n",
    "# Define a pattern to match the filenames of the CSV files\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Use glob to get a list of all files that match the pattern\n",
    "#filenames = glob.glob(input_path + pattern)\n",
    "\n",
    "# Or single filename:\n",
    "filenames = [\"data/promice/new_promice/daily_data/10_KAN_L.csv\"]#glob.glob(input_path + \"10_KAN_L.daily_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to define the dataname that is to be saved\n",
    "\n",
    "# Define the directory path where the CSV files are to be saved\n",
    "output_path = 'data/promice/preprocessed/daily_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m header\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_name\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# Headers are shifted in csv file\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# add delta column\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#df['Surface height from combined measurements DELTA'] = df['Surface height from combined measurements'].diff()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#df[\"Datetime\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating\u001b[39m\u001b[38;5;124m\"\u001b[39m , year)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Get the dataframe for the current year\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3770\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3766\u001b[0m is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n\u001b[1;32m   3767\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   3768\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m-> 3770\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_unique\u001b[49m\n\u001b[1;32m   3771\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3772\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3773\u001b[0m ):\n\u001b[1;32m   3774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:2386\u001b[0m, in \u001b[0;36mIndex.is_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_unique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;124;03m    Return if the index has unique values.\u001b[39;00m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_unique\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:225\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.is_unique.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:232\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._do_unique_check\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:290\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5778\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "# Percentiles for beginning & end of Ablation Period\n",
    "beginning = 0.15\n",
    "end = 0.85\n",
    "\n",
    "for file in filenames:\n",
    "    \n",
    "    # Load one station\n",
    "    df = load_daily(file)\n",
    "    #df = pd.read_csv(\"data/promice/new_promice/daily_data/10_KAN_L.daily_csv\")\n",
    "    \n",
    "    # defining ice ablation period   \n",
    "    smoothed_PT =  df['depth_of_pressure_transducer_in_ice_corrected'].interpolate(limit=72).rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "    smoothed_PT = smoothed_PT.rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "\n",
    "    threshold_ablation = -0.0002 # Modify value if needed\n",
    "    ind_ablation = np.logical_and(smoothed_PT.diff().values < threshold_ablation, \n",
    "                                  np.isin(smoothed_PT.diff().index.month, [6, 7, 8, 9]))\n",
    "\n",
    "    ind_ablation = np.concatenate((ind_ablation[4*24:], np.repeat(ind_ablation[-(4*24):-(4*24-1)], 4*24)))\n",
    "\n",
    "    df['Ablation'] = ind_ablation.tolist()\n",
    "\n",
    "    # add headers\n",
    "    df = df.rename(columns = header.set_index('long_name')['units']) # Headers are shifted in csv file\n",
    "\n",
    "\n",
    "    # add delta column\n",
    "    #df['Surface height from combined measurements DELTA'] = df['Surface height from combined measurements'].diff()\n",
    "\n",
    "\n",
    "    # This bit to add a beginning, middle & end of melting season attribute\n",
    "\n",
    "    # Iterate over each year\n",
    "    #df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    #df[\"Datetime\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    for year in df['Datetime'].dt.year.unique():\n",
    "\n",
    "        print(\"Calculating\" , year)\n",
    "\n",
    "        # Get the dataframe for the current year\n",
    "        year_df = df[df['Datetime'].dt.year == year]\n",
    "\n",
    "        # Determine the threshold values for the beginning and end of the melting season\n",
    "        ablation_df = year_df[year_df['Ablation'] == True]\n",
    "        lower_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(beginning)\n",
    "        upper_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(end)\n",
    "        pre_threshold = lower_threshold - 60\n",
    "\n",
    "        # Set the Melting Season value for each row in the current year\n",
    "        for index, row in year_df.iterrows():\n",
    "\n",
    "            if row['Ablation'] == True:\n",
    "                if row['Datetime'].dayofyear <= lower_threshold:\n",
    "                    df.loc[index, 'Melting Season'] = 'beginning'\n",
    "                elif row['Datetime'].dayofyear >= upper_threshold:\n",
    "                    df.loc[index, 'Melting Season'] = 'end'\n",
    "                else:\n",
    "                    df.loc[index, 'Melting Season'] = 'middle'\n",
    "            elif row['Ablation'] == False & row['Datetime'].dayofyear <= pre_threshold:\n",
    "                df.loc[index, 'Melting Season'] = 'pre' \n",
    "            else:\n",
    "                df.loc[index, 'Melting Season'] = ''\n",
    "\n",
    "    exclude = df[[column for column in df.columns if column not in exclude_list]]\n",
    "    df.to_csv(output_path + file, index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    701\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    703\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    704\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    705\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    706\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 707\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m callable(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:1064\u001b[0m, in \u001b[0;36mDataFrame.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1063\u001b[0m repr_params \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mget_dataframe_repr_params()\n\u001b[0;32m-> 1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepr_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:1245\u001b[0m, in \u001b[0;36mDataFrame.to_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_colwidth):\n\u001b[1;32m   1227\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mDataFrameFormatter(\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1229\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1244\u001b[0m     )\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:1136\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_string\u001b[0;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringFormatter\n\u001b[1;32m   1135\u001b[0m string_formatter \u001b[38;5;241m=\u001b[39m StringFormatter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt, line_width\u001b[38;5;241m=\u001b[39mline_width)\n\u001b[0;32m-> 1136\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mstring_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/string.py:30\u001b[0m, in \u001b[0;36mStringFormatter.to_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_string_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mshould_show_dimensions:\n\u001b[1;32m     32\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([text, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mdimensions_info])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/string.py:45\u001b[0m, in \u001b[0;36mStringFormatter._get_string_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_empty_info_line\n\u001b[0;32m---> 45\u001b[0m strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# no need to wrap around just print the whole frame\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj\u001b[38;5;241m.\u001b[39madjoin(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mstrcols)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/string.py:36\u001b[0m, in \u001b[0;36mStringFormatter._get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m---> 36\u001b[0m     strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mis_truncated:\n\u001b[1;32m     38\u001b[0m         strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_dot_separators(strcols)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:617\u001b[0m, in \u001b[0;36mDataFrameFormatter.get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    Render a DataFrame to a list of columns (as lists of strings).\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m     strcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_strcols_without_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m    620\u001b[0m         str_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_formatted_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtr_frame)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:872\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_strcols_without_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m     str_columns \u001b[38;5;241m=\u001b[39m [[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader]\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 872\u001b[0m     str_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_formatted_column_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtr_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_row_idx_names:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m str_columns:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:953\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_formatted_column_labels\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    951\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[1;32m    952\u001b[0m     need_leadsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(fmt_columns, \u001b[38;5;28mmap\u001b[39m(is_numeric_dtype, dtypes)))\n\u001b[0;32m--> 953\u001b[0m     str_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    954\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_formatter(i) \u001b[38;5;129;01mand\u001b[39;00m need_leadsp[x] \u001b[38;5;28;01melse\u001b[39;00m x]\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fmt_columns)\n\u001b[1;32m    956\u001b[0m     ]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;66;03m# self.str_columns = str_columns\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m str_columns\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:954\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    951\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[1;32m    952\u001b[0m     need_leadsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(fmt_columns, \u001b[38;5;28mmap\u001b[39m(is_numeric_dtype, dtypes)))\n\u001b[1;32m    953\u001b[0m     str_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 954\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m need_leadsp[x] \u001b[38;5;28;01melse\u001b[39;00m x]\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fmt_columns)\n\u001b[1;32m    956\u001b[0m     ]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;66;03m# self.str_columns = str_columns\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m str_columns\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:917\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_formatter\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(i) \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m    916\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m--> 917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:1106\u001b[0m, in \u001b[0;36mDataFrame._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     show_dimensions \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.show_dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1086\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mDataFrameFormatter(\n\u001b[1;32m   1087\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1088\u001b[0m         columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:1110\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_html\u001b[0;34m(self, buf, encoding, classes, notebook, border, table_id, render_links)\u001b[0m\n\u001b[1;32m   1101\u001b[0m Klass \u001b[38;5;241m=\u001b[39m NotebookFormatter \u001b[38;5;28;01mif\u001b[39;00m notebook \u001b[38;5;28;01melse\u001b[39;00m HTMLFormatter\n\u001b[1;32m   1103\u001b[0m html_formatter \u001b[38;5;241m=\u001b[39m Klass(\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1105\u001b[0m     classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     render_links\u001b[38;5;241m=\u001b[39mrender_links,\n\u001b[1;32m   1109\u001b[0m )\n\u001b[0;32m-> 1110\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mhtml_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:77\u001b[0m, in \u001b[0;36mHTMLFormatter.to_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lines):\n\u001b[1;32m     79\u001b[0m         lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:632\u001b[0m, in \u001b[0;36mNotebookFormatter.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<div>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_style()\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</div>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melements\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:83\u001b[0m, in \u001b[0;36mHTMLFormatter.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_show_dimensions:\n\u001b[1;32m     86\u001b[0m         by \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m215\u001b[39m)  \u001b[38;5;66;03m# ×\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:258\u001b[0m, in \u001b[0;36mHTMLFormatter._write_table\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mheader \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_row_idx_names:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_header(indent \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent_delta)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindent_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</table>\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:406\u001b[0m, in \u001b[0;36mHTMLFormatter._write_body\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_body\u001b[39m(\u001b[38;5;28mself\u001b[39m, indent: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<tbody>\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent)\n\u001b[0;32m--> 406\u001b[0m     fmt_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_formatted_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# write values\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:596\u001b[0m, in \u001b[0;36mNotebookFormatter._get_formatted_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_formatted_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {i: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt\u001b[38;5;241m.\u001b[39mformat_col(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncols)}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/html.py:596\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_formatted_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {i: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncols)}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:896\u001b[0m, in \u001b[0;36mDataFrameFormatter.format_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_col\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    895\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtr_frame\n\u001b[0;32m--> 896\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m format_array(\n\u001b[1;32m    898\u001b[0m         frame\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39m_values,\n\u001b[1;32m    899\u001b[0m         formatter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    904\u001b[0m         leading_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m    905\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py:917\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_formatter\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(i) \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m    916\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m--> 917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For All Stations - Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to define the data that is to be loaded\n",
    "\n",
    "import glob\n",
    "\n",
    "# Define the directory path where the CSV files are located\n",
    "input_path = 'data/promice/new_promice/hourly'\n",
    "\n",
    "# Define a pattern to match the filenames of the CSV files\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Use glob to get a list of all files that match the pattern\n",
    "filenames = glob.glob(input_path + pattern)\n",
    "\n",
    "# Or single filename:\n",
    "#filenames = glob.glob(\"KAN_L.daily_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit to define the dataname that is to be saved\n",
    "\n",
    "# Define the directory path where the CSV files are to be saved\n",
    "output_path = 'data/promice/preprocessed/hourly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles for beginning & end of Ablation Period\n",
    "beginning = 0.15\n",
    "end = 0.85\n",
    "\n",
    "for file in filenames:\n",
    "    \n",
    "    # Load one station\n",
    "    df = load_hourly(file)\n",
    "    \n",
    "    # defining ice ablation period   \n",
    "    smoothed_PT =  df['z_pt_cor'].interpolate(limit=72).rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "    smoothed_PT = smoothed_PT.rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "\n",
    "    threshold_ablation = -0.0002 # Modify value if needed\n",
    "    ind_ablation = np.logical_and(smoothed_PT.diff().values < threshold_ablation, \n",
    "                                  np.isin(smoothed_PT.diff().index.month, [6, 7, 8, 9]))\n",
    "\n",
    "    ind_ablation = np.concatenate((ind_ablation[4*24:], np.repeat(ind_ablation[-(4*24):-(4*24-1)], 4*24)))\n",
    "\n",
    "    df['Ablation'] = ind_ablation.tolist()\n",
    "\n",
    "    # add headers\n",
    "    df = df.rename(columns = header.set_index('standard_name')['units']) # Headers are shifted in csv file\n",
    "\n",
    "\n",
    "    # add delta column\n",
    "    df['Surface height from combined measurements DELTA'] = df['Surface height from combined measurements'].diff()\n",
    "\n",
    "\n",
    "    # This bit to add a beginning, middle & end of melting season attribute\n",
    "\n",
    "    # Iterate over each year\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    #df[\"Datetime\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    for year in df['Datetime'].dt.year.unique():\n",
    "\n",
    "        print(\"Calculating\" , year)\n",
    "\n",
    "        # Get the dataframe for the current year\n",
    "        year_df = df[df['Datetime'].dt.year == year]\n",
    "\n",
    "        # Determine the threshold values for the beginning and end of the melting season\n",
    "        ablation_df = year_df[year_df['Ablation'] == True]\n",
    "        lower_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(beginning)\n",
    "        upper_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(end)\n",
    "        pre_threshold = lower_threshold - 60\n",
    "\n",
    "        # Set the Melting Season value for each row in the current year\n",
    "        for index, row in year_df.iterrows():\n",
    "\n",
    "            if row['Ablation'] == True:\n",
    "                if row['Datetime'].dayofyear <= lower_threshold:\n",
    "                    df.loc[index, 'Melting Season'] = 'beginning'\n",
    "                elif row['Datetime'].dayofyear >= upper_threshold:\n",
    "                    df.loc[index, 'Melting Season'] = 'end'\n",
    "                else:\n",
    "                    df.loc[index, 'Melting Season'] = 'middle'\n",
    "            elif row['Ablation'] == False & row['Datetime'].dayofyear <= pre_threshold:\n",
    "                df.loc[index, 'Melting Season'] = 'pre' \n",
    "            else:\n",
    "                df.loc[index, 'Melting Season'] = ''\n",
    "\n",
    "    exclude = df[[column for column in df.columns if column not in exclude_list]]\n",
    "    df.to_csv(output_path + file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otherwise redo the steps just for KAN_L:\n",
    "\n",
    "os.chdir('/Users/nilsfulde/Desktop/GEUS-Master-Thesis')\n",
    "\n",
    "df = load_promice('data/new_promice/all_promice_data_daily.parquet.gzip')\n",
    "\n",
    "os.chdir('/Users/nilsfulde/Desktop/Master_Thesis')\n",
    "\n",
    "df = df[df[\"stid\"] == \"KAN_L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 2008\n",
      "Calculating 2009\n",
      "Calculating 2010\n",
      "Calculating 2011\n",
      "Calculating 2012\n",
      "Calculating 2013\n",
      "Calculating 2014\n",
      "Calculating 2015\n",
      "Calculating 2016\n",
      "Calculating 2017\n",
      "Calculating 2018\n",
      "Calculating 2019\n",
      "Calculating 2020\n",
      "Calculating 2021\n",
      "Calculating 2022\n",
      "Calculating 2023\n"
     ]
    }
   ],
   "source": [
    "# defining ice ablation period   \n",
    "smoothed_PT =  df['z_pt_cor'].interpolate(limit=72).rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "smoothed_PT = smoothed_PT.rolling('14D', min_periods=1).mean().shift(-7*14/2, freq='h')\n",
    "\n",
    "threshold_ablation = -0.0002 # Modify value if needed\n",
    "ind_ablation = np.logical_and(smoothed_PT.diff().values < threshold_ablation, \n",
    "                              np.isin(smoothed_PT.diff().index.month, [6, 7, 8, 9]))\n",
    "\n",
    "ind_ablation = np.concatenate((ind_ablation[4*24:], np.repeat(ind_ablation[-(4*24):-(4*24-1)], 4*24)))\n",
    "\n",
    "df['Ablation'] = ind_ablation.tolist()\n",
    "\n",
    "# add headers\n",
    "header = pd.read_csv('metadata/promice_header.csv', sep = \";\")\n",
    "df = df.rename(columns = header.set_index('standard_name')['units']) # Headers are shifted in csv file\n",
    "\n",
    "\n",
    "# add delta column (Modification Needed)\n",
    "df['Surface height from combined measurements DELTA'] = df['Surface height from combined measurements'].diff()\n",
    "\n",
    "\n",
    "\n",
    "# This bit to add a beginning, middle & end of melting season attribute\n",
    "beginning = 0.15\n",
    "end = 0.85\n",
    "\n",
    "# Iterate over each year\n",
    "#df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "for year in df['Datetime'].dt.year.unique():\n",
    "    \n",
    "    print(\"Calculating\" , year)\n",
    "    \n",
    "    # Get the dataframe for the current year\n",
    "    year_df = df[df['Datetime'].dt.year == year]\n",
    "    \n",
    "    # Determine the threshold values for the beginning and end of the melting season\n",
    "    ablation_df = year_df[year_df['Ablation'] == True]\n",
    "    lower_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(beginning)\n",
    "    upper_threshold = ablation_df['Datetime'].dt.dayofyear.quantile(end)\n",
    "    \n",
    "    # Set the Melting Season value for each row in the current year\n",
    "    for index, row in year_df.iterrows():\n",
    "        \n",
    "        if row['Ablation'] == True:\n",
    "            if row['Datetime'].dayofyear <= lower_threshold:\n",
    "                df.loc[index, 'Melting Season'] = 'beginning'\n",
    "            elif row['Datetime'].dayofyear >= upper_threshold:\n",
    "                df.loc[index, 'Melting Season'] = 'end'\n",
    "            else:\n",
    "                df.loc[index, 'Melting Season'] = 'middle'\n",
    "        else:\n",
    "            df.loc[index, 'Melting Season'] = ''\n",
    "            \n",
    "df.to_csv('data/KAN_L_daily.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
